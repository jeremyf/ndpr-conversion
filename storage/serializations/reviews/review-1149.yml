--- 
catalog_id: 2002.05.04
bibliography: McDermott, Drew V., <em>Mind and Mechanism</em>, The MIT Press, 2001, 262 pp, $32.95 (hbk), ISBN 0-262-13392-X.
images: []

review_id: 1149
content: "<p>When I finished reading this book, I was reminded of the opening stanza of <i>Spirit Song Over the Waters</i>, a poem by Johann Wolfgang Goethe:</p>   <blockquote>The soul of man\r\n\
  resembleth water:\r\n\
  From heaven it cometh,\r\n\
  To heaven it soareth,\r\n\
  And then again\r\n\
  To earth descendeth,\r\n Changing ever.</blockquote>  \t\t \n\
  <p>I now think that McDermott\xE2\x80\x99s closing lines (p. 241)\xE2\x80\x94and the general tone of the last chapter (Chapter 6)\xE2\x80\x94were instrumental in elevating my spirits:</p>  \t\t <blockquote>We must look for a coherent synthesis of our religious intuitions and scientific discoveries, so that as the very definition of what it is to be human changes, we will have a hope that our moral intuitions will not degenerate; or if not a hope, at least a prayer.</blockquote>  \t\t \n\
  <p>I\xE2\x80\x99ll later revisit this inspiring chapter and say a few more things about it. But let me start off this review with the usual question that faces any book reviewer. What is <i>Mind and Mechanism</i> about? Despite the experience I have just related, this book is not about ethical or religious affairs. (As a matter of fact, these arise only in Chapter 6.) A well-known AI researcher, McDermott is interested in computational approaches to consciousness. His reason for working in the field of AI is to solve the mind-body problem. In other words, his long-range goal is to understand how a physical organ, viz. the brain, can have experiences. This is a tough project because it involves the elucidation of the relationship between our mentality and the physical foundation of our body. How can a biological/chemical system (i.e., the human body) have beliefs, desires, intentions, and so on? Physicists have persuasive reasons to make us believe that ours is a material world (of particles at the bottommost level) that obeys physical laws. Once we commit ourselves to this view, it sounds quite bewildering\xE2\x80\x94even enigmatic\xE2\x80\x94to think that there is a place for independently existing minds in such a world.</p>   \n\
  <p>When physicists speak, McDermott listens. As he makes clear on the first page of Chapter 1, his hypothesis is that we are all contraptions designed by evolution. The concept of mind arises because people\xE2\x80\x99s brains are biological computers. Crudely put, minds are produced by computers. The whole book thus becomes an extended argument about how one can be more specific about the way this production is realized.</p>  \t\t <blockquote>The book consists of the following chapters:\r\n\
  1.The Problem of Phenomenal Consciousness (27 pp.)\r\n\
  2.Artificial Intelligence (63 pp.)\r\n\
  3.A Computational Theory of Consciousness (44 pp.)\r\n\
  4.Objections and Replies (29 pp.)\r\n\
  5.Symbols and Semantics (48 pp.)\r\n\
  6.Consequences (27 pp.)</blockquote>  \t\t \n\
  <p>Chapter 2, the longest, is a masterly account of the state of the art in AI. Discussed in this chapter are computational mechanisms for such classical problems of AI as game-playing (computer chess being the classic example), neural networks (including a clear discussion of the tensions between the symbolic vs. nonsymbolic approaches to AI), computer vision, robotics, speech-recognition/language-understanding, and automated theorem-proving. At first glance, this chapter looks like a stranger among the others. After all, this is the only chapter that reports technological advances (along with their underlying theoretical foundations, to be fair). But the author has a good reason for including it: to draw a clear boundary between what we can now build and what is sheer speculation (science fiction). Thus, when McDermott deliberates about computational mechanism in various other places in the book, he in fact is referring to mechanisms like the ones mentioned in Chapter 2.</p>   \n\
  <p>McDermott sees mind as a self-fulfilling description, a description that brings mind into being. He offers a fine analogy by considering the windows in the user interface of a personal computer. These windows are there because the computer is working in a way supporting their existence. It is able to do so by running procedures that use data structures\xE2\x80\x94textual descriptions portraying what the windows are to be like. In a nutshell, a formal description starts to act causatively when interpreted by a computer. In some sense, the mind is also a window, albeit one with a Herculean description.</p>   \n\
  <p>McDermott assigns great importance to models of the world. These models include models of the self. The self-model is the source of everything one knows about oneself. More interestingly, it is because of the self-model that one believes in free will. Subtract the self-model and you would end up with an entity which is not a fully functioning person anymore.</p>   \n\
  <p>For McDermott, the problem of phenomenal consciousness\xE2\x80\x94how a physical object can have experiences\xE2\x80\x94is the toughest nut to crack. To put the matter differently, explaining what it is to have qualia is the hardest problem. To this end, McDermott first tries to demystify the notion of free will. His insight is that a robot must model itself in a different way from other objects in its world in order to avoid infinite regress. Consider a straightforward cycle of events in the life of a robot, starting with perception, leading to making a tentative prediction, and concluding with revising an action. McDermott claims that this chain of events cannot be accurately embedded in a model unless the symbols denoting the robot itself are flagged as free from causality. (You\xE2\x80\x99ll have to read Chapter 3, pp. 97-98, to appreciate this fully.)</p>   \n\
  <p>This approach to explaining free will can also be used to explain away qualia. The key move is to notice that a sequence of goals must come to an end with a goal that can\xE2\x80\x99t be further questioned. Imagine a robot on a dangerous mission to save people from drowning in a river. As long as the robot is immersed in water, its underlying system can label wetness as \xE2\x80\x9Cundesirable but OK for the time being.\xE2\x80\x9D According to McDermott, at this point the robot\xE2\x80\x99s apprehension of wetness is analogous to a quale of disagreeableness. In representing this state, the robot classifies it as \xE2\x80\x9Cto be shunned or evaded as much as possible.\xE2\x80\x9D To cite another of McDermott\xE2\x80\x99s examples: \xE2\x80\x9C[A] robot may dislike going into burning buildings because it dislikes heat. But it doesn\xE2\x80\x99t dislike heat because of further bad consequences; high heat is <i>intrinsically</i> not-likable\xE2\x80\x9D (p. 102, my emphasis).</p>   \n\
  <p>But then there is no need for qualia in the computational system of a robot. Consciousness arises through the employment of a self-model and qualia are occasioned by the process of self-modeling. That means that what is manifested by our robot is virtual consciousness, which eventually boils down to physical events.</p>   \n\
  <p>Chapter 4 is devoted to a thorough defense of these proposals (formulated in Chapters 1 and 3) against various (some even classical) objections. Discussed in Chapter 5 are numerous full-fledged or partial theories of consciousness or related matters by influential philosophers, e.g. (in no particular order), Tye, Carruthers, Clark, Rey, Block, Chalmers, Jackson, Dennett, Shoemaker, Nagel, Lycan, Searle. Almost all of McDermott\xE2\x80\x99s arguments and analyses in this chapter are to the point, upright, and illuminating. His grasp of the contributions of the aforementioned people is commendable in its clarity.</p>   \n\
  <p>Chapter 5 is somewhat technical and treats a question which is not central to McDermott\xE2\x80\x99s general theory: the observer-relativity of symbols and semantics. A notable proponent of observer-relativity, Searle famously said, \xE2\x80\x9CFor any program and any sufficiently complex object, there is some description of the object under which it is implementing the program. Thus for example the wall behind my back is right now implementing the Wordstar program, because there is some pattern of molecule movements that is isomorphic with the formal structure of Wordstar.\xE2\x80\x9D McDermott\xE2\x80\x99s refutation of this dangerously relativistic viewpoint is based on his painstaking analysis of the notion of decoding, a mapping from a computer\xE2\x80\x99s states to its computational realm. It is then argued that while everything might be considered as a computer sometimes (with respect to some decoding), this fact does not endanger the concept of a computer. Using a clever continuity argument (small state perturbations causing little difference in the output), McDermott shows that if someone makes a Searlean claim of the sort just mentioned, then the burden of proof is on him to demonstrate that the continuity requirement is not violated.</p>   \n\
  <p>Assuming that McDermott\xE2\x80\x99s general views regarding the self and qualia are correct, an infamous question raises its head: is there anything precious or sacred about a person (= a machine)? The history of AI is replete with numerous instances of this question because people are (understandably) worried about the moral dimension of the AI enterprise. The question that has been asked for the umpteenth time, most recently in the flashy Spielberg movie <i>A.I.</i>, is this: can an artificial intelligence \xE2\x80\x9Cbe the subject or object of moral judgment?\xE2\x80\x9D (p. 217). McDermott states that a robot can have phenomenal consciousness but lack morals. If I understand him correctly, his argument for this is based on the behavior of a program. Assume we build a robot which is just like an average person when it comes to attributes such as love, morality, aesthetics, humor, etc. Now, it is conceivable that by just tweaking some program variables, we could get radically different (perhaps unrecognizable) versions of these attributes. Consequently,</p>  \t\t <blockquote>We\xE2\x80\x99ll take robot aesthetics [similarly, robot morals -VA] seriously if the robots ever reach a point where we can debate them, destroy them, or lobotomize them, but can\xE2\x80\x99t change their tastes [moral codes -VA] by adjusting a few lines of code. (p. 221)</blockquote>  \t\t \n\
  <p>The last big question that McDermott grapples with is belief in God in the absence of dualist nonphysical realms. His stance is not anti-religionist; he doesn\xE2\x80\x99t think that religion is a menacing force. Neither does he consider belief in God as a potentially short-lived activity in the broad development of civilization. McDermott is convinced that mankind will always be troubled by finiteness and long for the comfort provided by the unfathomable or incomprehensible. In a memorable passage, he writes:</p>  \t\t <blockquote>The only way to reconcile God\xE2\x80\x99s silence [remember Wittgenstein\xE2\x80\x99s closing remark in Zettel: \xE2\x80\x9CYou can\xE2\x80\x99t hear God speak to someone else, you can hear him only if you are being addressed.\xE2\x80\x9D -VA] with his existence is to assume that <i>he poured himself into the world when he created it</i>. His intervention in the world consists in creating laws of physics that allow complex physical systems to evolve that understand those very laws; in making it possible for weird creatures to evolve from monkeys and grasp the need for an overarching set of moral principles. [pp. 237-8, my emphasis]</blockquote>  \t\t \n\
  <p>McDermott\xE2\x80\x99s God is presumably one who does not answer prayers or does not prevent bad things from happening to good people. It is a God who turned \xE2\x80\x9Cus loose in such an uncaring world\xE2\x80\x9D (p. 239). But he takes a reverent stance: the only way for us is to accept the world as given and thank God for our existence. Thinking about what God wants us to do is good because otherwise there is a real danger of nonchalance and aberrant behavior (p. 238).</p>   \n\
  <p>To wrap up, one strength of this book is its almost encyclopedic coverage; it simply looks like the agenda of a busy philosopher of mind-language-and-morals. And while it may be surmised that in treating so many diverse concepts it is easy to fall into the trap of superficiality, I did not really notice anything of the sort. McDermott has this natural gift for explaining the knotty or perplexing with such grace and vividness that one cannot help but admire his virtuosity. Thus, his modesty and worries about not \xE2\x80\x9Cusing the usual philosophical tools to approach [philosophical questions]\xE2\x80\x9D (p. 24) or not conducting his discussions \xE2\x80\x9Cin the pure philosophical style\xE2\x80\x9D (p. 25) are definitely misplaced.</p>   \n\
  <p>Do I see any shortcomings of <i>Mind and Mechanism</i>? Well, probably just this one. Except for a passing remark (on something else), McDermott does not connect his proposal with the doctrines of Davidson. This is a pity because such a comparison would be promising, even fruitful. As many readers will know, Davidson has worked out an ingenious answer to the puzzle of the mental. Basically, he takes it for granted that the essential properties of matter as described by physicists are the only properties we have. Thus, he subscribes to some form of materialism. However, he thinks that one can be a materialist while also asserting that the mental cannot be reduced to the physical. Assume that you have complete knowledge in front of you of your brain and any relevant neurophysiological systems. According to Davidson, this knowledge cannot constitute knowledge of your beliefs, desires, intentions, etc. This he maintains without really taking a dualist stance, that is, without assuming that your mind has a separate kind of existence. Rather, his point is that our vocabulary for describing the mental does not match the concepts of physics in the right way. For example, he sees the principle of rationality as a most crucial aspect of the mental (especially belief), and holds that this principle has no echo in physical theory. Davidson\xE2\x80\x99s thesis is that the nature of mental phenomena does not permit law-like regularities connecting the mental phenomena with physical events in the brain.</p>   \n\
  <p>In the preface of his <i>The Seas of Language</i>, Michael Dummett offers useful advice. He hopes that readers might enjoy his papers and be stimulated to new approaches of their own. More importantly, he says that he does not expect agreement. I think the same comments can be made for <i>Mind and Mechanism</i>. In the space of a mere 250 pages McDermott spans the landscape of almost every important problem in computation, cognition and mind, while not causing indigestion (but presumably a lot of disagreement). A capable author in lucidly explaining the most intriguing phenomena, he formulates fine\xE2\x80\x94but tentative\xE2\x80\x94solutions for some of these vexed questions. If you want an intuitive (and frequently deeper) grasp of what is keeping philosophers of mind busy nowadays read this book. With the recent flurry of books and conferences (see <a href=\"**VERIFY**\">http://www.wired.com/news/technology/0,1282,51765,00.html</a> for a very recent one) on consciousness, it seems we are closer to filling the gap that discouraged William James. \xE2\x80\x9CWe know what consciousness is,\xE2\x80\x9D he once wrote, \xE2\x80\x9Cas long as no one asks us to define it.\xE2\x80\x9D</p>"
links: 
- http://www.wired.com/news/technology/0,1282,51765,00.html
authors: Drew V. McDermott
reviewer: Varol Akman, Bilkent University, Ankara
transformed_content: "<p>When I finished reading this book, I was reminded of the opening stanza of <i>Spirit Song Over the Waters</i>, a poem by Johann Wolfgang Goethe:</p>   <blockquote>The soul of man\r\n\
  resembleth water:\r\n\
  From heaven it cometh,\r\n\
  To heaven it soareth,\r\n\
  And then again\r\n\
  To earth descendeth,\r\n Changing ever.</blockquote>  \t\t \n\
  <p>I now think that McDermott\xE2\x80\x99s closing lines (p. 241)\xE2\x80\x94and the general tone of the last chapter (Chapter 6)\xE2\x80\x94were instrumental in elevating my spirits:</p>  \t\t <blockquote>We must look for a coherent synthesis of our religious intuitions and scientific discoveries, so that as the very definition of what it is to be human changes, we will have a hope that our moral intuitions will not degenerate; or if not a hope, at least a prayer.</blockquote>  \t\t \n\
  <p>I\xE2\x80\x99ll later revisit this inspiring chapter and say a few more things about it. But let me start off this review with the usual question that faces any book reviewer. What is <i>Mind and Mechanism</i> about? Despite the experience I have just related, this book is not about ethical or religious affairs. (As a matter of fact, these arise only in Chapter 6.) A well-known AI researcher, McDermott is interested in computational approaches to consciousness. His reason for working in the field of AI is to solve the mind-body problem. In other words, his long-range goal is to understand how a physical organ, viz. the brain, can have experiences. This is a tough project because it involves the elucidation of the relationship between our mentality and the physical foundation of our body. How can a biological/chemical system (i.e., the human body) have beliefs, desires, intentions, and so on? Physicists have persuasive reasons to make us believe that ours is a material world (of particles at the bottommost level) that obeys physical laws. Once we commit ourselves to this view, it sounds quite bewildering\xE2\x80\x94even enigmatic\xE2\x80\x94to think that there is a place for independently existing minds in such a world.</p>   \n\
  <p>When physicists speak, McDermott listens. As he makes clear on the first page of Chapter 1, his hypothesis is that we are all contraptions designed by evolution. The concept of mind arises because people\xE2\x80\x99s brains are biological computers. Crudely put, minds are produced by computers. The whole book thus becomes an extended argument about how one can be more specific about the way this production is realized.</p>  \t\t <blockquote>The book consists of the following chapters:\r\n\
  1.The Problem of Phenomenal Consciousness (27 pp.)\r\n\
  2.Artificial Intelligence (63 pp.)\r\n\
  3.A Computational Theory of Consciousness (44 pp.)\r\n\
  4.Objections and Replies (29 pp.)\r\n\
  5.Symbols and Semantics (48 pp.)\r\n\
  6.Consequences (27 pp.)</blockquote>  \t\t \n\
  <p>Chapter 2, the longest, is a masterly account of the state of the art in AI. Discussed in this chapter are computational mechanisms for such classical problems of AI as game-playing (computer chess being the classic example), neural networks (including a clear discussion of the tensions between the symbolic vs. nonsymbolic approaches to AI), computer vision, robotics, speech-recognition/language-understanding, and automated theorem-proving. At first glance, this chapter looks like a stranger among the others. After all, this is the only chapter that reports technological advances (along with their underlying theoretical foundations, to be fair). But the author has a good reason for including it: to draw a clear boundary between what we can now build and what is sheer speculation (science fiction). Thus, when McDermott deliberates about computational mechanism in various other places in the book, he in fact is referring to mechanisms like the ones mentioned in Chapter 2.</p>   \n\
  <p>McDermott sees mind as a self-fulfilling description, a description that brings mind into being. He offers a fine analogy by considering the windows in the user interface of a personal computer. These windows are there because the computer is working in a way supporting their existence. It is able to do so by running procedures that use data structures\xE2\x80\x94textual descriptions portraying what the windows are to be like. In a nutshell, a formal description starts to act causatively when interpreted by a computer. In some sense, the mind is also a window, albeit one with a Herculean description.</p>   \n\
  <p>McDermott assigns great importance to models of the world. These models include models of the self. The self-model is the source of everything one knows about oneself. More interestingly, it is because of the self-model that one believes in free will. Subtract the self-model and you would end up with an entity which is not a fully functioning person anymore.</p>   \n\
  <p>For McDermott, the problem of phenomenal consciousness\xE2\x80\x94how a physical object can have experiences\xE2\x80\x94is the toughest nut to crack. To put the matter differently, explaining what it is to have qualia is the hardest problem. To this end, McDermott first tries to demystify the notion of free will. His insight is that a robot must model itself in a different way from other objects in its world in order to avoid infinite regress. Consider a straightforward cycle of events in the life of a robot, starting with perception, leading to making a tentative prediction, and concluding with revising an action. McDermott claims that this chain of events cannot be accurately embedded in a model unless the symbols denoting the robot itself are flagged as free from causality. (You\xE2\x80\x99ll have to read Chapter 3, pp. 97-98, to appreciate this fully.)</p>   \n\
  <p>This approach to explaining free will can also be used to explain away qualia. The key move is to notice that a sequence of goals must come to an end with a goal that can\xE2\x80\x99t be further questioned. Imagine a robot on a dangerous mission to save people from drowning in a river. As long as the robot is immersed in water, its underlying system can label wetness as \xE2\x80\x9Cundesirable but OK for the time being.\xE2\x80\x9D According to McDermott, at this point the robot\xE2\x80\x99s apprehension of wetness is analogous to a quale of disagreeableness. In representing this state, the robot classifies it as \xE2\x80\x9Cto be shunned or evaded as much as possible.\xE2\x80\x9D To cite another of McDermott\xE2\x80\x99s examples: \xE2\x80\x9C[A] robot may dislike going into burning buildings because it dislikes heat. But it doesn\xE2\x80\x99t dislike heat because of further bad consequences; high heat is <i>intrinsically</i> not-likable\xE2\x80\x9D (p. 102, my emphasis).</p>   \n\
  <p>But then there is no need for qualia in the computational system of a robot. Consciousness arises through the employment of a self-model and qualia are occasioned by the process of self-modeling. That means that what is manifested by our robot is virtual consciousness, which eventually boils down to physical events.</p>   \n\
  <p>Chapter 4 is devoted to a thorough defense of these proposals (formulated in Chapters 1 and 3) against various (some even classical) objections. Discussed in Chapter 5 are numerous full-fledged or partial theories of consciousness or related matters by influential philosophers, e.g. (in no particular order), Tye, Carruthers, Clark, Rey, Block, Chalmers, Jackson, Dennett, Shoemaker, Nagel, Lycan, Searle. Almost all of McDermott\xE2\x80\x99s arguments and analyses in this chapter are to the point, upright, and illuminating. His grasp of the contributions of the aforementioned people is commendable in its clarity.</p>   \n\
  <p>Chapter 5 is somewhat technical and treats a question which is not central to McDermott\xE2\x80\x99s general theory: the observer-relativity of symbols and semantics. A notable proponent of observer-relativity, Searle famously said, \xE2\x80\x9CFor any program and any sufficiently complex object, there is some description of the object under which it is implementing the program. Thus for example the wall behind my back is right now implementing the Wordstar program, because there is some pattern of molecule movements that is isomorphic with the formal structure of Wordstar.\xE2\x80\x9D McDermott\xE2\x80\x99s refutation of this dangerously relativistic viewpoint is based on his painstaking analysis of the notion of decoding, a mapping from a computer\xE2\x80\x99s states to its computational realm. It is then argued that while everything might be considered as a computer sometimes (with respect to some decoding), this fact does not endanger the concept of a computer. Using a clever continuity argument (small state perturbations causing little difference in the output), McDermott shows that if someone makes a Searlean claim of the sort just mentioned, then the burden of proof is on him to demonstrate that the continuity requirement is not violated.</p>   \n\
  <p>Assuming that McDermott\xE2\x80\x99s general views regarding the self and qualia are correct, an infamous question raises its head: is there anything precious or sacred about a person (= a machine)? The history of AI is replete with numerous instances of this question because people are (understandably) worried about the moral dimension of the AI enterprise. The question that has been asked for the umpteenth time, most recently in the flashy Spielberg movie <i>A.I.</i>, is this: can an artificial intelligence \xE2\x80\x9Cbe the subject or object of moral judgment?\xE2\x80\x9D (p. 217). McDermott states that a robot can have phenomenal consciousness but lack morals. If I understand him correctly, his argument for this is based on the behavior of a program. Assume we build a robot which is just like an average person when it comes to attributes such as love, morality, aesthetics, humor, etc. Now, it is conceivable that by just tweaking some program variables, we could get radically different (perhaps unrecognizable) versions of these attributes. Consequently,</p>  \t\t <blockquote>We\xE2\x80\x99ll take robot aesthetics [similarly, robot morals -VA] seriously if the robots ever reach a point where we can debate them, destroy them, or lobotomize them, but can\xE2\x80\x99t change their tastes [moral codes -VA] by adjusting a few lines of code. (p. 221)</blockquote>  \t\t \n\
  <p>The last big question that McDermott grapples with is belief in God in the absence of dualist nonphysical realms. His stance is not anti-religionist; he doesn\xE2\x80\x99t think that religion is a menacing force. Neither does he consider belief in God as a potentially short-lived activity in the broad development of civilization. McDermott is convinced that mankind will always be troubled by finiteness and long for the comfort provided by the unfathomable or incomprehensible. In a memorable passage, he writes:</p>  \t\t <blockquote>The only way to reconcile God\xE2\x80\x99s silence [remember Wittgenstein\xE2\x80\x99s closing remark in Zettel: \xE2\x80\x9CYou can\xE2\x80\x99t hear God speak to someone else, you can hear him only if you are being addressed.\xE2\x80\x9D -VA] with his existence is to assume that <i>he poured himself into the world when he created it</i>. His intervention in the world consists in creating laws of physics that allow complex physical systems to evolve that understand those very laws; in making it possible for weird creatures to evolve from monkeys and grasp the need for an overarching set of moral principles. [pp. 237-8, my emphasis]</blockquote>  \t\t \n\
  <p>McDermott\xE2\x80\x99s God is presumably one who does not answer prayers or does not prevent bad things from happening to good people. It is a God who turned \xE2\x80\x9Cus loose in such an uncaring world\xE2\x80\x9D (p. 239). But he takes a reverent stance: the only way for us is to accept the world as given and thank God for our existence. Thinking about what God wants us to do is good because otherwise there is a real danger of nonchalance and aberrant behavior (p. 238).</p>   \n\
  <p>To wrap up, one strength of this book is its almost encyclopedic coverage; it simply looks like the agenda of a busy philosopher of mind-language-and-morals. And while it may be surmised that in treating so many diverse concepts it is easy to fall into the trap of superficiality, I did not really notice anything of the sort. McDermott has this natural gift for explaining the knotty or perplexing with such grace and vividness that one cannot help but admire his virtuosity. Thus, his modesty and worries about not \xE2\x80\x9Cusing the usual philosophical tools to approach [philosophical questions]\xE2\x80\x9D (p. 24) or not conducting his discussions \xE2\x80\x9Cin the pure philosophical style\xE2\x80\x9D (p. 25) are definitely misplaced.</p>   \n\
  <p>Do I see any shortcomings of <i>Mind and Mechanism</i>? Well, probably just this one. Except for a passing remark (on something else), McDermott does not connect his proposal with the doctrines of Davidson. This is a pity because such a comparison would be promising, even fruitful. As many readers will know, Davidson has worked out an ingenious answer to the puzzle of the mental. Basically, he takes it for granted that the essential properties of matter as described by physicists are the only properties we have. Thus, he subscribes to some form of materialism. However, he thinks that one can be a materialist while also asserting that the mental cannot be reduced to the physical. Assume that you have complete knowledge in front of you of your brain and any relevant neurophysiological systems. According to Davidson, this knowledge cannot constitute knowledge of your beliefs, desires, intentions, etc. This he maintains without really taking a dualist stance, that is, without assuming that your mind has a separate kind of existence. Rather, his point is that our vocabulary for describing the mental does not match the concepts of physics in the right way. For example, he sees the principle of rationality as a most crucial aspect of the mental (especially belief), and holds that this principle has no echo in physical theory. Davidson\xE2\x80\x99s thesis is that the nature of mental phenomena does not permit law-like regularities connecting the mental phenomena with physical events in the brain.</p>   \n\
  <p>In the preface of his <i>The Seas of Language</i>, Michael Dummett offers useful advice. He hopes that readers might enjoy his papers and be stimulated to new approaches of their own. More importantly, he says that he does not expect agreement. I think the same comments can be made for <i>Mind and Mechanism</i>. In the space of a mere 250 pages McDermott spans the landscape of almost every important problem in computation, cognition and mind, while not causing indigestion (but presumably a lot of disagreement). A capable author in lucidly explaining the most intriguing phenomena, he formulates fine\xE2\x80\x94but tentative\xE2\x80\x94solutions for some of these vexed questions. If you want an intuitive (and frequently deeper) grasp of what is keeping philosophers of mind busy nowadays read this book. With the recent flurry of books and conferences (see <a href=\"**VERIFY**\">http://www.wired.com/news/technology/0,1282,51765,00.html</a> for a very recent one) on consciousness, it seems we are closer to filling the gap that discouraged William James. \xE2\x80\x9CWe know what consciousness is,\xE2\x80\x9D he once wrote, \xE2\x80\x9Cas long as no one asks us to define it.\xE2\x80\x9D</p>"
review_title: Mind and Mechanism
