--- 
catalog_id: 2003.11.10
review_id: 1307
images: []

bibliography: Swinburne, Richard (ed.), <em>Bayes's Theorem</em>, Oxford University Press, 2002, 160pp, $24.95 (hbk), ISBN 0197262678.
links: []

content: "<p>This is a high quality, concise collection of articles on the foundations of probability and statistics. Its editor, Richard Swinburne, has collected five papers by contemporary leaders in the field, written a pretty thorough and even-handed introductory essay, and placed a very clean and accessible version of Reverend Thomas Bayes\xE2\x80\x99s famous essay (\xE2\x80\x9CAn Essay Towards the Solving a Problem in the Doctrine of Chances\xE2\x80\x9D) at the end, as an Appendix (with a brief historical introduction by the noted statistician G.A. Barnard). I will briefly discuss each of the five papers in the volume, with an emphasis on certain issues arising from the use of probability as a tool for thinking about <i>evidence</i>.</p>  \n\
  <p>In the first essay, Elliott Sober contrasts Bayesian accounts of evidential support with an alternative, non-Bayesian, likelihood-based approach. The crux of Sober\xE2\x80\x99s non-Bayesian proposal involves the following sort of claim about <i>contrastive</i> evidential support:</p>  <blockquote>Evidence <i>E</i> favors hypothesis <i>H</i><sub>1</sub> over hypothesis <i>H</i><sub>2</sub>.</blockquote>  \n\
  <p>Here, the alternative hypotheses <i>H</i><sub>1</sub> and <i>H</i><sub>2</sub> need not be mutually exclusive. Sober proposes that we should unpack this relational concept of favoring using <i>likelihoods</i>, as follows:</p>  <blockquote>Evidence <i>E</i> favors hypothesis <i>H</i><sub>1</sub> over hypothesis <i>H</i><sub>2</sub> if Pr(<i>E</i> | <i>H</i><sub>1</sub>) > Pr(E | <i>H</i><sub>2</sub>).</blockquote>  \n\
  <p>This principle is sometimes called the \xE2\x80\x9CLaw of Likelihood\xE2\x80\x9D (see Royall (1997) for the history and theoretical basis of this \xE2\x80\x9Claw\xE2\x80\x9D). From a Bayesian (and, I think, <i>intuitive</i> point of view), this \xE2\x80\x9Claw\xE2\x80\x9D is far from obvious.  Consider a case in which <i>E</i> entails <i>H</i><sub>1</sub> but fails to entail <i>H</i><sub>2</sub>. Intuitively, in such a case, <i>E</i> should <i>favor H</i><sub>1</sub>over <i>H</i><sub>2</sub>. After all, E <i>guarantees</i> the truth of <i>H</i><sub>1</sub>, but fails to guarantee the truth of <i>H</i><sub>2</sub>.  It is important to note that the \xE2\x80\x9CLaw of Likelihood\xE2\x80\x9D is <i>inconsistent</i> with this intuitive principle. That is, there can be cases in which Pr(<i>E</i> | <i>H</i><sub>1</sub>) > Pr(E | <i>H</i><sub>2</sub>), <i>despite</i> the fact that <i>E</i> entails <i>H</i><sub>2</sub> but fails to entail <i>H</i><sub>1</sub>. Of course, these will be cases in which <i>H</i><sub>1</sub> and <i>H</i><sub>2</sub> are <i>not</i> mutually exclusive, but a <i>likelihoodist</i> cannot object to such counterexamples on <i>these</i> grounds (since mutual exclusivity is <i>not</i> a requirement for the likelihoodist\xE2\x80\x99s \xE2\x80\x9Cfavoring\xE2\x80\x9D relation). A proper, Bayesian theory of contrastive confirmation, on the other hand, need not have this undesirable consequence.</p>  \n\
  <p>Bayesians typically understand relational support in terms of <i>non</i>-contrastive <i>confirmation</i>. For a Bayesian, <i>E</i> supports (or confirms) <i>H</i> \xE2\x80\x93 in a <i>non</i>-contrastive sense \xE2\x80\x93 just in case <i>E</i> raises the probability of <i>H</i> (on a suitable, rational credence function). There have been various proposals concerning how a Bayesian ought to measure the <i>degree</i> to which <i>E</i> confirms <i>H</i>, or <i>c</i>(<i>H</i>, <i>E</i>), for short (see Fitelson (1998) for a survey). But, no matter which Bayesian <i>c</i>-measure one favors, one would be inclined to define <i>contrastive</i> support (or <i>favoring</i>) in terms of this <i>non</i>-contrastive confirmation measure <i>c</i>, as follows:</p>  <blockquote>Evidence <i>E</i> favors hypothesis <i>H</i><sub>1</sub> over hypothesis <i>H</i><sub>2</sub> if <i>c</i>(<i>H</i><sub>1</sub>, <i>E</i>) > <i>c</i>(<i>H</i><sub>2</sub>, <i>E</i>).</blockquote>  \n\
  <p>Interestingly, this \xE2\x80\x9Creduction\xE2\x80\x9D of contrastive support to non-contrastive (Bayesian) confirmation need not be at odds with the \xE2\x80\x9CLaw of Likelihood\xE2\x80\x9D. As it turns out, there is one (and only one, out of all the historical proposals!) Bayesian measure of confirmation that <i>entails</i> the \xE2\x80\x9CLaw of Likelihood\xE2\x80\x9D, assuming this standard Bayesian definition of favoring in terms of confirmation (see Milne (1996)). This is important, as it shows that the Bayesian need not reject the \xE2\x80\x9CLaw of Likelihood.\xE2\x80\x9D However, those who think the \xE2\x80\x9Claw\xE2\x80\x9D is false (like myself) would be forced either to abandon the reductive principle stated above, or to choose a different measure of non-contrastive confirmation. Indeed, many have opted for the latter approach. While I would recommend endorsing <i>both</i> the former approach <i>and</i> the latter approach, it is worth mentioning that the following <i>weakened</i> version of the \xE2\x80\x9CLaw of Likelihood\xE2\x80\x9D should be acceptable to <i>all</i> parties here, Bayesian or otherwise:</p>  <blockquote>Evidence <i>E</i> favors hypothesis <i>H</i><sub>1</sub> over hypothesis <i>H</i><sub>2</sub> if</blockquote>  <blockquote>Pr(<i>E</i> | <i>H</i><sub>1</sub>) > Pr(E | <i>H</i><sub>2</sub>) <i>and</i> Pr(<i>E</i> | \xC2\xAC<i>H</i><sub>1</sub>) \xE2\x89\xA4 Pr(E | \xC2\xAC<i>H</i><sub>2</sub>).</blockquote>  \n\
  <p>Joyce (2003) shows that this principle is satisfied by <i>all</i> reductive Bayesian confirmation-theoretic approaches to favoring (that is, <i>all</i> Bayesian measures of confirmation <i>c</i> will lead to definitions of \xE2\x80\x9Cfavoring\xE2\x80\x9D that satisfy this weak likelihood principle). This is a nice way to see precisely where Bayesian and non-Bayesian accounts of evidential support come apart. Bayesians are perfectly happy to talk about the likelihoods of the <i>denials</i> of alternative hypotheses: Pr(E | \xC2\xAC<i>H</i><sub>1</sub>) and Pr(E | \xC2\xAC<i>H</i><sub>2</sub>). But, non-Bayesian Likelihoodists will not feel comfortable with such probabilities, since they involve <i>averaging</i> over the likelihoods of concrete alternative hypotheses. And, the \xE2\x80\x9Cweights\xE2\x80\x9D in these averages will depend on the dreaded <i>prior probabilities</i> of the alternative hypotheses: Pr(<i>H</i><sub>1</sub>) and Pr(<i>H</i><sub>2</sub>). While Bayesians are happy to use priors in their account of evidential support, non-Bayesians like Sober are strongly opposed to such a move, since they think the prior probabilities are (in general) subjective and that they lack probative force. Ultimately, it seems to me, whether terms like Pr(<i>E</i> | \xC2\xAC<i>H</i><sub>1</sub>) should be countenanced in our theory of evidence will depend on the overall relative adequacy of Bayesian <i>vs</i> non-Bayesian accounts of evidential support. Howson (pp. 52\xE2\x80\x9353) argues in his contribution to this volume that such likelihoods are <i>crucial</i> for properly understanding evidential support. And, I am inclined to agree (see Fitelson (2001) for some further reasons why). Indeed, even <i>non</i>-Bayesians will use such terms <i>sometimes</i> \xE2\x80\x94 when it seems to be <i>essential</i> to obtaining the right answers about <i>contrastive</i> evidential support (see Royall (1997, pages 1\xE2\x80\x932), and even Sober (2003) for some clear examples of this kind).</p>  \n\
  <p>Sober\xE2\x80\x99s paper concludes with a discussion of recent <i>instrumentalist</i>, non-Bayesian approaches to statistical inference. Here, he highlights the work of the Japanese statistician Akaike, which aims to show how the <i>simplicity</i> of a model can be tied to its <i>predictive accuracy</i>. This is a very important area of research in contemporary statistics and also in the philosophy of science. Sober argues that Bayesian approaches to these issues and problems cannot adequately account for the importance of simplicity as a factor in determining how predictively accurate a statistical model is. Howson, and other Bayesians, are usually not convinced by such arguments. And, in fairness to the Bayesian approaches, I think there is more that can be said on this score (for a nice Bayesian discussion of simplicity in this context, see Rosenkrantz (1977)). I conclude my discussion of Sober\xE2\x80\x99s paper with a detail that the minute reader may find puzzling. In the first part of his paper, Sober talks about \xE2\x80\x9Cfavoring,\xE2\x80\x9D which, presumably, involves evidence favoring the <i>truth</i> of one hypothesis over another (not, say, favoring the <i>predictive accuracy</i> of one over another), but in the second part he talks only about comparative judgments of <i>predictive accuracy</i> and <i>not</i> about truth. It is unclear to me how the likelihoods appearing in Akaike\xE2\x80\x99s theorem are to be interpreted. Are they still capturing what the evidence says about the <i>truth</i> of competing theories, or are they merely containing information relevant to assessing relative <i>predictive accuracy</i>? It is interesting that (either way) likelihoods would then seem to be essential <i>both</i> to the instrumentalist <i>and</i> to the non-instrumentalist (who is concerned with evidence regarding the <i>truth</i> of competing theories). It would be nice to know how and why likelihoods are able to play this dual role.</p>  \n\
  <p>In contrast to Sober\xE2\x80\x99s contribution to this volume, the papers of Howson, Dawid, and Earman adopt a Bayesian stance. The first part of Howson\xE2\x80\x99s paper contains a wealth of historical, philosophical, and statistical wisdom. He discusses the role of Bayesian methods (and, by contrast, some of their most notable non-Bayesian rivals) in statistical theory and practice, beginning with the very first Bayesian methods used by Laplace (and Bayes himself), leading all the way up to the most recent foundational issues addressed by Bayesian statisticians and philosophers, including debates about \xE2\x80\x9Cinformationless\xE2\x80\x9D prior probabilities, and the importance of simplicity in hypothesis (or model) choice. Howson\xE2\x80\x99s treatments of Fisherian and Neyman-Pearsonian statistical methods (and philosophies) are particularly informative and useful (the analogies with Popperian and hypothetico-deductive conceptions should be especially illuminating for philosophers). And, Howson\xE2\x80\x99s discussion of Lindley\xE2\x80\x99s Paradox is refreshing (it seems to me that not enough philosophical ink has been spilt over this important statistical conundrum).</p>  \n\
  <p>The second part of Howson\xE2\x80\x99s paper (on which I will dwell a bit) is written from a more \xE2\x80\x9Clogical\xE2\x80\x9D point of view. Here, he proposes a systematic, and general Bayesian (non-deductive, of course) \xE2\x80\x9Clogic,\xE2\x80\x9D which is described in a way that makes it sound strongly analogous to (classical) <i>deductive</i> logic. He talks about \xE2\x80\x9Cconsistency\xE2\x80\x9D and \xE2\x80\x9Csoundness\xE2\x80\x9D and \xE2\x80\x9Ccompleteness\xE2\x80\x9D, <i>etc</i>. Some of the logicians among us will probably have deep worries about this analogy, and no doubt they will view use of this logical terminology as a non-trivial stretch. I must confess, I found myself feeling rather uncomfortable about the degree of force with which Howson pushes the analogy. I will focus here on Howson\xE2\x80\x99s notion of \xE2\x80\x9Cinconsistency,\xE2\x80\x9D but I think similar worries will apply to his other \xE2\x80\x9Clogical\xE2\x80\x9D notions. When a (classical) logician talks about <i>inconsistency</i>, it is a notion that is <i>directly</i> relevant not only to decision-making and other (broadly) pragmatic disciplines, but also to <i>epistemology</i> (understood here in a traditional, <i>non-pragmatic</i> sense). It\xE2\x80\x99s not entirely clear to me that Howson\xE2\x80\x99s notion of \xE2\x80\x9Cconsistency\xE2\x80\x9D has such direct relevance to epistemology. Here, I am <i>not</i> worrying about the problems involving prior probabilities mentioned above. I am willing to <i>grant</i> (<i>arguendo</i>) that <i>they</i> <i>do</i> have epistemic and probative force. What I do not see is why someone who is \xE2\x80\x9Cinconsistent\xE2\x80\x9D in Howson\xE2\x80\x99s sense should feel any <i>epistemic</i> pressure to revise their degrees of belief. It seems logically consistent with Howson\xE2\x80\x99s \xE2\x80\x9Cinconsistency\xE2\x80\x9D that such an agent\xE2\x80\x99s degrees of belief are <i>inter alia</i> as accurate as they have ever been (or ever will be).  This is (arguably) <i>not</i> the case when the agent\xE2\x80\x99s beliefs are <i>logically</i> inconsistent. In that case, the agent <i>knows</i> there is something <i>false</i> in what they believe (and this is transparently a <i>bad thing</i>, from an epistemic point of view). What is the analogous thing that an \xE2\x80\x9Cinconsistent\xE2\x80\x9D agent (in Howson\xE2\x80\x99s sense) <i>knows</i> that would inspire them to change their degrees of belief? In this connection, it seems to me that Howson\xE2\x80\x99s discussion is somewhat vague. He presents his \xE2\x80\x9Clogic\xE2\x80\x9D without crucial details concerning the proofs of the key theorems that purport to forge the strong analogy between deductive logic and his Bayesian \xE2\x80\x9Clogic\xE2\x80\x9D. For instance, Howson does not explain how the additivity axiom follows from his \xE2\x80\x9Cconsistency\xE2\x80\x9D assumptions (indeed, he even claims to establish the \xE2\x80\x9Cinconsistency\xE2\x80\x9D of violations of <i>countable</i> additivity, which is <i>even more</i> controversial). This leaves one wondering whether the compelling objections to Dutch Book arguments that have been voiced by philosophers like Schick (1980) and Maher (1993) might have some bearing on Howson\xE2\x80\x99s approach. Such philosophers seem to provide examples of cases in which it seems perfectly <i>rational</i> to violate the additivity axiom (and, therefore, Howson\xE2\x80\x99s \xE2\x80\x9Cconsistency\xE2\x80\x9D). It would be nice to hear Howson explain what, precisely, makes such agent\xE2\x80\x99s degrees of belief \xE2\x80\x9Cbad\xE2\x80\x9D or \xE2\x80\x9Cirrational\xE2\x80\x9D (in <i>any</i> compelling sense). More traditional logicians may want to have a look at Carnap\xE2\x80\x99s (1950) insightful discussion of the relationship between deductive and inductive logic. Carnap\xE2\x80\x99s inductive logic program may have failed, but its aim was to provide a notion of partial entailment that was <i>logical</i> in the <i>very same sense</i> (not merely in an <i>analogous</i> sense) that deductive logical consequence is <i>logical</i>, and thereby to <i>avoid</i> a pragmatic and/or subjective turn in inductive logic (which seems implicit \xE2\x80\x93 although now deeply buried \xE2\x80\x93in Howson\xE2\x80\x99s talk of \xE2\x80\x9Cbetting quotients\xE2\x80\x9D and \xE2\x80\x9Cfairness\xE2\x80\x9D). It seems to me that this aim may still be achievable (albeit, probably in a non-Carnapian way), and until it is demonstrated that this goal cannot be achieved, perhaps it would make more sense to reserve the term \xE2\x80\x9Clogic\xE2\x80\x9D for the non-pragmatic, non-contingent, and objective conception that traditional logicians have in mind. In the meantime, why not just stick with the term \xE2\x80\x9Crational\xE2\x80\x9D, as opposed to \xE2\x80\x9Clogical\xE2\x80\x9D when characterizing Bayesian accounts of credence? Would anything really be lost?</p>   \n\
  <p>Dawid\xE2\x80\x99s paper provides a very clear, simple, and sound introduction to the use of Bayesian theories of evidential support (and weighing evidence) in legal contexts. A fair amount of work has been done in this area over the past thirty years or so, and Dawid\xE2\x80\x99s paper serves as a nice overview of the basic techniques that are applied by Bayesians in the context of legal evidence. One of the best things Dawid does is to make very clear the distinction between prior probabilities (degrees of <i>belief</i>) and likelihood ratios (degrees of <i>support</i> or <i>weight of evidence</i>). Many of the same issues discussed above in connection with Bayesian theories of evidential support arise in concrete and simple examples in Dawid\xE2\x80\x99s paper. Dawid proposes the likelihood ratio measure <i>l</i>(<i>H</i>, <i>E</i>) = Pr(<i>E</i> | <i>H</i>) / Pr(<i>E</i> | \xC2\xAC<i>H</i>) as the proper Bayesian measure of degree of support. This measure has been skillfully defended by I.J. Good for many years (see Good (1985)), and more recently has been shown to have various advantages over other Bayesian measures of confirmation (see Eells and Fitelson (2000), and Fitelson (2001)). Importantly, because of its sensitivity to the \xE2\x80\x9Ccatch-all\xE2\x80\x9D likelihood Pr(<i>E</i> | \xC2\xAC<i>H</i>), <i>l</i> <i>violates</i> the strong \xE2\x80\x9CLaw of Likelihood\xE2\x80\x9D discussed above (endorsed by Sober). And, yet, as Dawid\xE2\x80\x99s examples illustrate, it often seems <i>crucial</i> to take account of such terms in our assessments (both contrastive and non-contrastive) of weight of evidence. In this sense, Dawid\xE2\x80\x99s legal examples provide a nice testbed for clashing intuitions in the Bayes/non-Bayes controversy about evidential support. I think Dawid\xE2\x80\x99s examples provide further reasons to worry about the legitimacy of the strong \xE2\x80\x9CLaw of Likelihood,\xE2\x80\x9D and further reasons to retreat to Joyce\xE2\x80\x99s (2003) <i>Weak</i> Law of Likelihood.</p>   \n\
  <p>Earman\xE2\x80\x99s paper can be viewed as a sampler of a much longer essay he has written [Earman (2000)] on Hume\xE2\x80\x99s arguments concerning miracles (an essay which I highly recommend, by the way). Earman provides a detailed historical trace of the arguments of Hume and his contemporaries concerning the possibility of compelling testimony about the occurrence of miracles. By carefully and skillfully applying Bayesian techniques to these arguments, Earman ends up with some very interesting (albeit somewhat anachronistic) new reconstructions of these infamous historical arguments. By and large, Earman\xE2\x80\x99s reconstructions are accurate and novel, and his analyses are trenchant. His Bayesian treatment of multiple testimonial reports is especially illuminating. The only complaint I have about this paper is that it may focus too heavily on <i>posterior probabilities</i> Pr(<i>H</i> | <i>E</i>) of the various hypotheses <i>H</i> in question, given the various sorts of evidence <i>E</i> he considers. It would also be interesting to see parallel analyses done which focus more on the <i>likelihood ratios</i> <i>l</i>(<i>H</i>, <i>E</i>) that result in each of the reconstructions. I suspect the ensuing facts about <i>degree of support</i> would be harmonious with Earman\xE2\x80\x99s conclusions about <i>degrees of belief</i> in these cases. But, examining things from the <i>weight of evidence</i> perspective (as Dawid does in the legal context) may shed further light on some of the issues and arguments. This is a minor complaint, and Earman is to be commended for the rich historical/philosophical tale he tells, and for the interesting applications of Bayesian machinery he musters.</p>  \n\
  <p>The final contemporary paper in this collection (aside from Swinburne\xE2\x80\x99s solid introductory piece on which I have chosen not to comment explicitly) is Miller\xE2\x80\x99s brief (but important) essay on the propensity interpretation of probability. Roughly, the propensity theory recommends interpreting Pr(<i>X</i> | <i>Y</i>) as the (presumably, <i>causal</i>) <i>propensity</i> <i>Y</i> has for bringing about <i>X</i> (usually, in some experimental context). Popper (1957) was one of the first to endorse a propensity interpretation of conditional probability, and many others have followed suit since. Humphreys (1985) pointed out that there seem to be deep problems with the existence and interpretation of the \xE2\x80\x9Cinverse propensity\xE2\x80\x9D Pr(<i>Y</i> | <i>X</i>), since (presumably) <i>Y</i>\xE2\x80\x99s having a causal propensity to bring about <i>X</i> does <i>not</i> imply <i>X</i>\xE2\x80\x99s having a causal propensity to bring about <i>Y</i>. But, if \xE2\x80\x9CPr\xE2\x80\x9D is to satisfy the probability axioms, then it must also satisfy <i>Bayes\xE2\x80\x99s Theorem</i>, which would imply a perfectly well-defined and interpretable <i>inverse probability</i> Pr(<i>Y</i> | <i>X</i>). This became known as Humphreys\xE2\x80\x99s Paradox. Many people came to believe that Humphreys had shown that propensities <i>cannot</i> satisfy the axioms of probability (or Bayes\xE2\x80\x99s Theorem). [Indeed, it seems that some people already believed this before Humphreys\xE2\x80\x99 paper appeared (see Fetzer and Nute (1980)).] In his contribution to the volume, David Miller shows that this is not the case. Indeed, Miller sketches a perfectly coherent and sensible propensity theory that is also a <i>probability theory</i>. As such, Miller shows how to diffuse Humphreys\xE2\x80\x99s Paradox and restore the satisfaction of Bayes\xE2\x80\x99s Theorem for propensities. As it turns out, there are various ways to mitigate Humphreys\xE2\x80\x99 paradox in this sense. See Gillies (2001) for extended discussion of several approaches, including Miller\xE2\x80\x99s.</p>  \n\
  <p>The volume closes with an Appendix containing a very polished reproduction of Bayes\xE2\x80\x99s classic \xE2\x80\x9CAn Essay Towards the Solving a Problem in the Doctrine of Chances\xE2\x80\x9D. The Essay still reads very well, and it should be on every probabilist\xE2\x80\x99s \xE2\x80\x9Cmust read\xE2\x80\x9D list. I feel quite comfortable saying something almost as glowing about this entire volume. I found this book very edifying and clear, and the debates and issues it encompasses are of great importance for contemporary philosophy of probability, statistics, and decision-making. I highly recommend this book to anyone with interests in these areas, and I commend Swinburne for putting together this neat little book.<span style=\"font-weight: bold;\">\r\n\
  </span></p> \n\
  <p><span style=\"font-weight: bold;\">References</span></p>      <p class=\"cit\">Carnap, R., 1950, <i>Logical Foundations of Probability</i>, Chicago: University of Chicago Press.</p>  <p class=\"cit\">Earman, J., 2000, Hume\xE2\x80\x99s Abject Failure - The Argument Against Miracles, Oxford: Oxford University Press.</p>  <p class=\"cit\">Eells, E. and Fitelson, B., 2002, \xE2\x80\x9CSymmetries and Asymmetries in Evidential Support,\xE2\x80\x9D <i>Philosophical Studies</i> 107: 129\xE2\x80\x93142.</p>  <p class=\"cit\">Fetzer, J. and Nute, D., 1980, \xE2\x80\x9CA Probabilistic Causal Calculus: Conflicting Conceptions,\xE2\x80\x9D <i>Synthese</i> 44: 241-246.</p>  <p class=\"cit\">Fitelson, B., 1999, \xE2\x80\x9CThe plurality of Bayesian measures of confirmation and the problem of measure sensitivity.\xE2\x80\x9D <i>Philosophy of Science</i> 66: S362\xE2\x80\x93S378.</p>  <p class=\"cit\">Fitelson, B., 2001, \xE2\x80\x9CA Bayesian Account of Independent Evidence with Applications,\xE2\x80\x9D <i>Philosophy of Science</i> 68: S123\xE2\x80\x93S140.</p>  <p class=\"cit\">Gillies, D., 2000, \xE2\x80\x9CVarieties of Propensity\xE2\x80\x9D, <i>British Journal for the Philosophy of Science</i> 51: 807\xE2\x80\x93835.</p>  <p class=\"cit\">Good, I. (1985). \xE2\x80\x9CWeight of evidence: A brief survey,\xE2\x80\x9D In <i>Bayesian Statistics, 2</i> (Valencia, 1983), pp. 249\xE2\x80\x93269. Amsterdam: North-Holland. </p>  <p class=\"cit\">Humphreys, P., 1985, \xE2\x80\x9CWhy propensities cannot be probabilities,\xE2\x80\x9D <i>The Philosophical Review</i> 94: 557\xE2\x80\x93570.</p>  <p class=\"cit\">Joyce, J., 2003, \xE2\x80\x9CBayes\xE2\x80\x99 Theorem\xE2\x80\x9D, <i>The Stanford Encyclopedia of Philosophy</i> (Fall 2003 Edition), Edward N. Zalta (<i>ed</i>.), URL = http://plato.stanford.edu/entries/bayes-theorem/</p>  <p class=\"cit\">Maher, P., 1993, <i>Betting on Theories</i>. Cambridge: Cambridge University Press.</p>  <p class=\"cit\">Milne, P., 1996, \xE2\x80\x9CLog[<i>p</i>(<i>h/eb</i>)<i>/p</i>(<i>h/b</i>)] is the one true measure of confirmation,\xE2\x80\x9D <i>Philosophy of Science</i> 63: 21\xE2\x80\x9326.</p>  <p class=\"cit\">Popper, K., 1957, \xE2\x80\x9CThe propensity interpretation of the calculus of probability, and the Quantum Theory,\xE2\x80\x9D in S. K\xC3\xB6rner (<i>ed</i>.): <i>Observation and Interpretation in the Philosophy of Physics</i>.</p>  <p class=\"cit\">Rosenkrantz, R., 1977, <i>Inference, Method and Decision</i>. Dordrecht: D. Reidel.</p>  <p class=\"cit\">Royall, R., 1997, <i>Statistical Evidence: A Likelihood Paradigm</i>. London: Chapman &amp; Hall.</p>  <p class=\"cit\">Schick, F., 1986, \xE2\x80\x9CDutch Bookies and Money Pumps,\xE2\x80\x9D <i>Journal of Philosophy</i> 83: 112\xE2\x80\x93119.</p>  <p class=\"cit\">Sober, E., 2003, \xE2\x80\x9CLikelihood and the Duhem/Quine Problem,\xE2\x80\x9D unpublished manuscript.</p>"
authors: Richard Swinburne (ed.)
transformed_content: "<p>This is a high quality, concise collection of articles on the foundations of probability and statistics. Its editor, Richard Swinburne, has collected five papers by contemporary leaders in the field, written a pretty thorough and even-handed introductory essay, and placed a very clean and accessible version of Reverend Thomas Bayes\xE2\x80\x99s famous essay (\xE2\x80\x9CAn Essay Towards the Solving a Problem in the Doctrine of Chances\xE2\x80\x9D) at the end, as an Appendix (with a brief historical introduction by the noted statistician G.A. Barnard). I will briefly discuss each of the five papers in the volume, with an emphasis on certain issues arising from the use of probability as a tool for thinking about <i>evidence</i>.</p>  \n\
  <p>In the first essay, Elliott Sober contrasts Bayesian accounts of evidential support with an alternative, non-Bayesian, likelihood-based approach. The crux of Sober\xE2\x80\x99s non-Bayesian proposal involves the following sort of claim about <i>contrastive</i> evidential support:</p>  <blockquote>Evidence <i>E</i> favors hypothesis <i>H</i><sub>1</sub> over hypothesis <i>H</i><sub>2</sub>.</blockquote>  \n\
  <p>Here, the alternative hypotheses <i>H</i><sub>1</sub> and <i>H</i><sub>2</sub> need not be mutually exclusive. Sober proposes that we should unpack this relational concept of favoring using <i>likelihoods</i>, as follows:</p>  <blockquote>Evidence <i>E</i> favors hypothesis <i>H</i><sub>1</sub> over hypothesis <i>H</i><sub>2</sub> if Pr(<i>E</i> | <i>H</i><sub>1</sub>) > Pr(E | <i>H</i><sub>2</sub>).</blockquote>  \n\
  <p>This principle is sometimes called the \xE2\x80\x9CLaw of Likelihood\xE2\x80\x9D (see Royall (1997) for the history and theoretical basis of this \xE2\x80\x9Claw\xE2\x80\x9D). From a Bayesian (and, I think, <i>intuitive</i> point of view), this \xE2\x80\x9Claw\xE2\x80\x9D is far from obvious.  Consider a case in which <i>E</i> entails <i>H</i><sub>1</sub> but fails to entail <i>H</i><sub>2</sub>. Intuitively, in such a case, <i>E</i> should <i>favor H</i><sub>1</sub>over <i>H</i><sub>2</sub>. After all, E <i>guarantees</i> the truth of <i>H</i><sub>1</sub>, but fails to guarantee the truth of <i>H</i><sub>2</sub>.  It is important to note that the \xE2\x80\x9CLaw of Likelihood\xE2\x80\x9D is <i>inconsistent</i> with this intuitive principle. That is, there can be cases in which Pr(<i>E</i> | <i>H</i><sub>1</sub>) > Pr(E | <i>H</i><sub>2</sub>), <i>despite</i> the fact that <i>E</i> entails <i>H</i><sub>2</sub> but fails to entail <i>H</i><sub>1</sub>. Of course, these will be cases in which <i>H</i><sub>1</sub> and <i>H</i><sub>2</sub> are <i>not</i> mutually exclusive, but a <i>likelihoodist</i> cannot object to such counterexamples on <i>these</i> grounds (since mutual exclusivity is <i>not</i> a requirement for the likelihoodist\xE2\x80\x99s \xE2\x80\x9Cfavoring\xE2\x80\x9D relation). A proper, Bayesian theory of contrastive confirmation, on the other hand, need not have this undesirable consequence.</p>  \n\
  <p>Bayesians typically understand relational support in terms of <i>non</i>-contrastive <i>confirmation</i>. For a Bayesian, <i>E</i> supports (or confirms) <i>H</i> \xE2\x80\x93 in a <i>non</i>-contrastive sense \xE2\x80\x93 just in case <i>E</i> raises the probability of <i>H</i> (on a suitable, rational credence function). There have been various proposals concerning how a Bayesian ought to measure the <i>degree</i> to which <i>E</i> confirms <i>H</i>, or <i>c</i>(<i>H</i>, <i>E</i>), for short (see Fitelson (1998) for a survey). But, no matter which Bayesian <i>c</i>-measure one favors, one would be inclined to define <i>contrastive</i> support (or <i>favoring</i>) in terms of this <i>non</i>-contrastive confirmation measure <i>c</i>, as follows:</p>  <blockquote>Evidence <i>E</i> favors hypothesis <i>H</i><sub>1</sub> over hypothesis <i>H</i><sub>2</sub> if <i>c</i>(<i>H</i><sub>1</sub>, <i>E</i>) > <i>c</i>(<i>H</i><sub>2</sub>, <i>E</i>).</blockquote>  \n\
  <p>Interestingly, this \xE2\x80\x9Creduction\xE2\x80\x9D of contrastive support to non-contrastive (Bayesian) confirmation need not be at odds with the \xE2\x80\x9CLaw of Likelihood\xE2\x80\x9D. As it turns out, there is one (and only one, out of all the historical proposals!) Bayesian measure of confirmation that <i>entails</i> the \xE2\x80\x9CLaw of Likelihood\xE2\x80\x9D, assuming this standard Bayesian definition of favoring in terms of confirmation (see Milne (1996)). This is important, as it shows that the Bayesian need not reject the \xE2\x80\x9CLaw of Likelihood.\xE2\x80\x9D However, those who think the \xE2\x80\x9Claw\xE2\x80\x9D is false (like myself) would be forced either to abandon the reductive principle stated above, or to choose a different measure of non-contrastive confirmation. Indeed, many have opted for the latter approach. While I would recommend endorsing <i>both</i> the former approach <i>and</i> the latter approach, it is worth mentioning that the following <i>weakened</i> version of the \xE2\x80\x9CLaw of Likelihood\xE2\x80\x9D should be acceptable to <i>all</i> parties here, Bayesian or otherwise:</p>  <blockquote>Evidence <i>E</i> favors hypothesis <i>H</i><sub>1</sub> over hypothesis <i>H</i><sub>2</sub> if</blockquote>  <blockquote>Pr(<i>E</i> | <i>H</i><sub>1</sub>) > Pr(E | <i>H</i><sub>2</sub>) <i>and</i> Pr(<i>E</i> | \xC2\xAC<i>H</i><sub>1</sub>) \xE2\x89\xA4 Pr(E | \xC2\xAC<i>H</i><sub>2</sub>).</blockquote>  \n\
  <p>Joyce (2003) shows that this principle is satisfied by <i>all</i> reductive Bayesian confirmation-theoretic approaches to favoring (that is, <i>all</i> Bayesian measures of confirmation <i>c</i> will lead to definitions of \xE2\x80\x9Cfavoring\xE2\x80\x9D that satisfy this weak likelihood principle). This is a nice way to see precisely where Bayesian and non-Bayesian accounts of evidential support come apart. Bayesians are perfectly happy to talk about the likelihoods of the <i>denials</i> of alternative hypotheses: Pr(E | \xC2\xAC<i>H</i><sub>1</sub>) and Pr(E | \xC2\xAC<i>H</i><sub>2</sub>). But, non-Bayesian Likelihoodists will not feel comfortable with such probabilities, since they involve <i>averaging</i> over the likelihoods of concrete alternative hypotheses. And, the \xE2\x80\x9Cweights\xE2\x80\x9D in these averages will depend on the dreaded <i>prior probabilities</i> of the alternative hypotheses: Pr(<i>H</i><sub>1</sub>) and Pr(<i>H</i><sub>2</sub>). While Bayesians are happy to use priors in their account of evidential support, non-Bayesians like Sober are strongly opposed to such a move, since they think the prior probabilities are (in general) subjective and that they lack probative force. Ultimately, it seems to me, whether terms like Pr(<i>E</i> | \xC2\xAC<i>H</i><sub>1</sub>) should be countenanced in our theory of evidence will depend on the overall relative adequacy of Bayesian <i>vs</i> non-Bayesian accounts of evidential support. Howson (pp. 52\xE2\x80\x9353) argues in his contribution to this volume that such likelihoods are <i>crucial</i> for properly understanding evidential support. And, I am inclined to agree (see Fitelson (2001) for some further reasons why). Indeed, even <i>non</i>-Bayesians will use such terms <i>sometimes</i> \xE2\x80\x94 when it seems to be <i>essential</i> to obtaining the right answers about <i>contrastive</i> evidential support (see Royall (1997, pages 1\xE2\x80\x932), and even Sober (2003) for some clear examples of this kind).</p>  \n\
  <p>Sober\xE2\x80\x99s paper concludes with a discussion of recent <i>instrumentalist</i>, non-Bayesian approaches to statistical inference. Here, he highlights the work of the Japanese statistician Akaike, which aims to show how the <i>simplicity</i> of a model can be tied to its <i>predictive accuracy</i>. This is a very important area of research in contemporary statistics and also in the philosophy of science. Sober argues that Bayesian approaches to these issues and problems cannot adequately account for the importance of simplicity as a factor in determining how predictively accurate a statistical model is. Howson, and other Bayesians, are usually not convinced by such arguments. And, in fairness to the Bayesian approaches, I think there is more that can be said on this score (for a nice Bayesian discussion of simplicity in this context, see Rosenkrantz (1977)). I conclude my discussion of Sober\xE2\x80\x99s paper with a detail that the minute reader may find puzzling. In the first part of his paper, Sober talks about \xE2\x80\x9Cfavoring,\xE2\x80\x9D which, presumably, involves evidence favoring the <i>truth</i> of one hypothesis over another (not, say, favoring the <i>predictive accuracy</i> of one over another), but in the second part he talks only about comparative judgments of <i>predictive accuracy</i> and <i>not</i> about truth. It is unclear to me how the likelihoods appearing in Akaike\xE2\x80\x99s theorem are to be interpreted. Are they still capturing what the evidence says about the <i>truth</i> of competing theories, or are they merely containing information relevant to assessing relative <i>predictive accuracy</i>? It is interesting that (either way) likelihoods would then seem to be essential <i>both</i> to the instrumentalist <i>and</i> to the non-instrumentalist (who is concerned with evidence regarding the <i>truth</i> of competing theories). It would be nice to know how and why likelihoods are able to play this dual role.</p>  \n\
  <p>In contrast to Sober\xE2\x80\x99s contribution to this volume, the papers of Howson, Dawid, and Earman adopt a Bayesian stance. The first part of Howson\xE2\x80\x99s paper contains a wealth of historical, philosophical, and statistical wisdom. He discusses the role of Bayesian methods (and, by contrast, some of their most notable non-Bayesian rivals) in statistical theory and practice, beginning with the very first Bayesian methods used by Laplace (and Bayes himself), leading all the way up to the most recent foundational issues addressed by Bayesian statisticians and philosophers, including debates about \xE2\x80\x9Cinformationless\xE2\x80\x9D prior probabilities, and the importance of simplicity in hypothesis (or model) choice. Howson\xE2\x80\x99s treatments of Fisherian and Neyman-Pearsonian statistical methods (and philosophies) are particularly informative and useful (the analogies with Popperian and hypothetico-deductive conceptions should be especially illuminating for philosophers). And, Howson\xE2\x80\x99s discussion of Lindley\xE2\x80\x99s Paradox is refreshing (it seems to me that not enough philosophical ink has been spilt over this important statistical conundrum).</p>  \n\
  <p>The second part of Howson\xE2\x80\x99s paper (on which I will dwell a bit) is written from a more \xE2\x80\x9Clogical\xE2\x80\x9D point of view. Here, he proposes a systematic, and general Bayesian (non-deductive, of course) \xE2\x80\x9Clogic,\xE2\x80\x9D which is described in a way that makes it sound strongly analogous to (classical) <i>deductive</i> logic. He talks about \xE2\x80\x9Cconsistency\xE2\x80\x9D and \xE2\x80\x9Csoundness\xE2\x80\x9D and \xE2\x80\x9Ccompleteness\xE2\x80\x9D, <i>etc</i>. Some of the logicians among us will probably have deep worries about this analogy, and no doubt they will view use of this logical terminology as a non-trivial stretch. I must confess, I found myself feeling rather uncomfortable about the degree of force with which Howson pushes the analogy. I will focus here on Howson\xE2\x80\x99s notion of \xE2\x80\x9Cinconsistency,\xE2\x80\x9D but I think similar worries will apply to his other \xE2\x80\x9Clogical\xE2\x80\x9D notions. When a (classical) logician talks about <i>inconsistency</i>, it is a notion that is <i>directly</i> relevant not only to decision-making and other (broadly) pragmatic disciplines, but also to <i>epistemology</i> (understood here in a traditional, <i>non-pragmatic</i> sense). It\xE2\x80\x99s not entirely clear to me that Howson\xE2\x80\x99s notion of \xE2\x80\x9Cconsistency\xE2\x80\x9D has such direct relevance to epistemology. Here, I am <i>not</i> worrying about the problems involving prior probabilities mentioned above. I am willing to <i>grant</i> (<i>arguendo</i>) that <i>they</i> <i>do</i> have epistemic and probative force. What I do not see is why someone who is \xE2\x80\x9Cinconsistent\xE2\x80\x9D in Howson\xE2\x80\x99s sense should feel any <i>epistemic</i> pressure to revise their degrees of belief. It seems logically consistent with Howson\xE2\x80\x99s \xE2\x80\x9Cinconsistency\xE2\x80\x9D that such an agent\xE2\x80\x99s degrees of belief are <i>inter alia</i> as accurate as they have ever been (or ever will be).  This is (arguably) <i>not</i> the case when the agent\xE2\x80\x99s beliefs are <i>logically</i> inconsistent. In that case, the agent <i>knows</i> there is something <i>false</i> in what they believe (and this is transparently a <i>bad thing</i>, from an epistemic point of view). What is the analogous thing that an \xE2\x80\x9Cinconsistent\xE2\x80\x9D agent (in Howson\xE2\x80\x99s sense) <i>knows</i> that would inspire them to change their degrees of belief? In this connection, it seems to me that Howson\xE2\x80\x99s discussion is somewhat vague. He presents his \xE2\x80\x9Clogic\xE2\x80\x9D without crucial details concerning the proofs of the key theorems that purport to forge the strong analogy between deductive logic and his Bayesian \xE2\x80\x9Clogic\xE2\x80\x9D. For instance, Howson does not explain how the additivity axiom follows from his \xE2\x80\x9Cconsistency\xE2\x80\x9D assumptions (indeed, he even claims to establish the \xE2\x80\x9Cinconsistency\xE2\x80\x9D of violations of <i>countable</i> additivity, which is <i>even more</i> controversial). This leaves one wondering whether the compelling objections to Dutch Book arguments that have been voiced by philosophers like Schick (1980) and Maher (1993) might have some bearing on Howson\xE2\x80\x99s approach. Such philosophers seem to provide examples of cases in which it seems perfectly <i>rational</i> to violate the additivity axiom (and, therefore, Howson\xE2\x80\x99s \xE2\x80\x9Cconsistency\xE2\x80\x9D). It would be nice to hear Howson explain what, precisely, makes such agent\xE2\x80\x99s degrees of belief \xE2\x80\x9Cbad\xE2\x80\x9D or \xE2\x80\x9Cirrational\xE2\x80\x9D (in <i>any</i> compelling sense). More traditional logicians may want to have a look at Carnap\xE2\x80\x99s (1950) insightful discussion of the relationship between deductive and inductive logic. Carnap\xE2\x80\x99s inductive logic program may have failed, but its aim was to provide a notion of partial entailment that was <i>logical</i> in the <i>very same sense</i> (not merely in an <i>analogous</i> sense) that deductive logical consequence is <i>logical</i>, and thereby to <i>avoid</i> a pragmatic and/or subjective turn in inductive logic (which seems implicit \xE2\x80\x93 although now deeply buried \xE2\x80\x93in Howson\xE2\x80\x99s talk of \xE2\x80\x9Cbetting quotients\xE2\x80\x9D and \xE2\x80\x9Cfairness\xE2\x80\x9D). It seems to me that this aim may still be achievable (albeit, probably in a non-Carnapian way), and until it is demonstrated that this goal cannot be achieved, perhaps it would make more sense to reserve the term \xE2\x80\x9Clogic\xE2\x80\x9D for the non-pragmatic, non-contingent, and objective conception that traditional logicians have in mind. In the meantime, why not just stick with the term \xE2\x80\x9Crational\xE2\x80\x9D, as opposed to \xE2\x80\x9Clogical\xE2\x80\x9D when characterizing Bayesian accounts of credence? Would anything really be lost?</p>   \n\
  <p>Dawid\xE2\x80\x99s paper provides a very clear, simple, and sound introduction to the use of Bayesian theories of evidential support (and weighing evidence) in legal contexts. A fair amount of work has been done in this area over the past thirty years or so, and Dawid\xE2\x80\x99s paper serves as a nice overview of the basic techniques that are applied by Bayesians in the context of legal evidence. One of the best things Dawid does is to make very clear the distinction between prior probabilities (degrees of <i>belief</i>) and likelihood ratios (degrees of <i>support</i> or <i>weight of evidence</i>). Many of the same issues discussed above in connection with Bayesian theories of evidential support arise in concrete and simple examples in Dawid\xE2\x80\x99s paper. Dawid proposes the likelihood ratio measure <i>l</i>(<i>H</i>, <i>E</i>) = Pr(<i>E</i> | <i>H</i>) / Pr(<i>E</i> | \xC2\xAC<i>H</i>) as the proper Bayesian measure of degree of support. This measure has been skillfully defended by I.J. Good for many years (see Good (1985)), and more recently has been shown to have various advantages over other Bayesian measures of confirmation (see Eells and Fitelson (2000), and Fitelson (2001)). Importantly, because of its sensitivity to the \xE2\x80\x9Ccatch-all\xE2\x80\x9D likelihood Pr(<i>E</i> | \xC2\xAC<i>H</i>), <i>l</i> <i>violates</i> the strong \xE2\x80\x9CLaw of Likelihood\xE2\x80\x9D discussed above (endorsed by Sober). And, yet, as Dawid\xE2\x80\x99s examples illustrate, it often seems <i>crucial</i> to take account of such terms in our assessments (both contrastive and non-contrastive) of weight of evidence. In this sense, Dawid\xE2\x80\x99s legal examples provide a nice testbed for clashing intuitions in the Bayes/non-Bayes controversy about evidential support. I think Dawid\xE2\x80\x99s examples provide further reasons to worry about the legitimacy of the strong \xE2\x80\x9CLaw of Likelihood,\xE2\x80\x9D and further reasons to retreat to Joyce\xE2\x80\x99s (2003) <i>Weak</i> Law of Likelihood.</p>   \n\
  <p>Earman\xE2\x80\x99s paper can be viewed as a sampler of a much longer essay he has written [Earman (2000)] on Hume\xE2\x80\x99s arguments concerning miracles (an essay which I highly recommend, by the way). Earman provides a detailed historical trace of the arguments of Hume and his contemporaries concerning the possibility of compelling testimony about the occurrence of miracles. By carefully and skillfully applying Bayesian techniques to these arguments, Earman ends up with some very interesting (albeit somewhat anachronistic) new reconstructions of these infamous historical arguments. By and large, Earman\xE2\x80\x99s reconstructions are accurate and novel, and his analyses are trenchant. His Bayesian treatment of multiple testimonial reports is especially illuminating. The only complaint I have about this paper is that it may focus too heavily on <i>posterior probabilities</i> Pr(<i>H</i> | <i>E</i>) of the various hypotheses <i>H</i> in question, given the various sorts of evidence <i>E</i> he considers. It would also be interesting to see parallel analyses done which focus more on the <i>likelihood ratios</i> <i>l</i>(<i>H</i>, <i>E</i>) that result in each of the reconstructions. I suspect the ensuing facts about <i>degree of support</i> would be harmonious with Earman\xE2\x80\x99s conclusions about <i>degrees of belief</i> in these cases. But, examining things from the <i>weight of evidence</i> perspective (as Dawid does in the legal context) may shed further light on some of the issues and arguments. This is a minor complaint, and Earman is to be commended for the rich historical/philosophical tale he tells, and for the interesting applications of Bayesian machinery he musters.</p>  \n\
  <p>The final contemporary paper in this collection (aside from Swinburne\xE2\x80\x99s solid introductory piece on which I have chosen not to comment explicitly) is Miller\xE2\x80\x99s brief (but important) essay on the propensity interpretation of probability. Roughly, the propensity theory recommends interpreting Pr(<i>X</i> | <i>Y</i>) as the (presumably, <i>causal</i>) <i>propensity</i> <i>Y</i> has for bringing about <i>X</i> (usually, in some experimental context). Popper (1957) was one of the first to endorse a propensity interpretation of conditional probability, and many others have followed suit since. Humphreys (1985) pointed out that there seem to be deep problems with the existence and interpretation of the \xE2\x80\x9Cinverse propensity\xE2\x80\x9D Pr(<i>Y</i> | <i>X</i>), since (presumably) <i>Y</i>\xE2\x80\x99s having a causal propensity to bring about <i>X</i> does <i>not</i> imply <i>X</i>\xE2\x80\x99s having a causal propensity to bring about <i>Y</i>. But, if \xE2\x80\x9CPr\xE2\x80\x9D is to satisfy the probability axioms, then it must also satisfy <i>Bayes\xE2\x80\x99s Theorem</i>, which would imply a perfectly well-defined and interpretable <i>inverse probability</i> Pr(<i>Y</i> | <i>X</i>). This became known as Humphreys\xE2\x80\x99s Paradox. Many people came to believe that Humphreys had shown that propensities <i>cannot</i> satisfy the axioms of probability (or Bayes\xE2\x80\x99s Theorem). [Indeed, it seems that some people already believed this before Humphreys\xE2\x80\x99 paper appeared (see Fetzer and Nute (1980)).] In his contribution to the volume, David Miller shows that this is not the case. Indeed, Miller sketches a perfectly coherent and sensible propensity theory that is also a <i>probability theory</i>. As such, Miller shows how to diffuse Humphreys\xE2\x80\x99s Paradox and restore the satisfaction of Bayes\xE2\x80\x99s Theorem for propensities. As it turns out, there are various ways to mitigate Humphreys\xE2\x80\x99 paradox in this sense. See Gillies (2001) for extended discussion of several approaches, including Miller\xE2\x80\x99s.</p>  \n\
  <p>The volume closes with an Appendix containing a very polished reproduction of Bayes\xE2\x80\x99s classic \xE2\x80\x9CAn Essay Towards the Solving a Problem in the Doctrine of Chances\xE2\x80\x9D. The Essay still reads very well, and it should be on every probabilist\xE2\x80\x99s \xE2\x80\x9Cmust read\xE2\x80\x9D list. I feel quite comfortable saying something almost as glowing about this entire volume. I found this book very edifying and clear, and the debates and issues it encompasses are of great importance for contemporary philosophy of probability, statistics, and decision-making. I highly recommend this book to anyone with interests in these areas, and I commend Swinburne for putting together this neat little book.<span style=\"font-weight: bold;\">\r\n\
  </span></p> \n\
  <p><span style=\"font-weight: bold;\">References</span></p>      <p class=\"cit\">Carnap, R., 1950, <i>Logical Foundations of Probability</i>, Chicago: University of Chicago Press.</p>  <p class=\"cit\">Earman, J., 2000, Hume\xE2\x80\x99s Abject Failure - The Argument Against Miracles, Oxford: Oxford University Press.</p>  <p class=\"cit\">Eells, E. and Fitelson, B., 2002, \xE2\x80\x9CSymmetries and Asymmetries in Evidential Support,\xE2\x80\x9D <i>Philosophical Studies</i> 107: 129\xE2\x80\x93142.</p>  <p class=\"cit\">Fetzer, J. and Nute, D., 1980, \xE2\x80\x9CA Probabilistic Causal Calculus: Conflicting Conceptions,\xE2\x80\x9D <i>Synthese</i> 44: 241-246.</p>  <p class=\"cit\">Fitelson, B., 1999, \xE2\x80\x9CThe plurality of Bayesian measures of confirmation and the problem of measure sensitivity.\xE2\x80\x9D <i>Philosophy of Science</i> 66: S362\xE2\x80\x93S378.</p>  <p class=\"cit\">Fitelson, B., 2001, \xE2\x80\x9CA Bayesian Account of Independent Evidence with Applications,\xE2\x80\x9D <i>Philosophy of Science</i> 68: S123\xE2\x80\x93S140.</p>  <p class=\"cit\">Gillies, D., 2000, \xE2\x80\x9CVarieties of Propensity\xE2\x80\x9D, <i>British Journal for the Philosophy of Science</i> 51: 807\xE2\x80\x93835.</p>  <p class=\"cit\">Good, I. (1985). \xE2\x80\x9CWeight of evidence: A brief survey,\xE2\x80\x9D In <i>Bayesian Statistics, 2</i> (Valencia, 1983), pp. 249\xE2\x80\x93269. Amsterdam: North-Holland. </p>  <p class=\"cit\">Humphreys, P., 1985, \xE2\x80\x9CWhy propensities cannot be probabilities,\xE2\x80\x9D <i>The Philosophical Review</i> 94: 557\xE2\x80\x93570.</p>  <p class=\"cit\">Joyce, J., 2003, \xE2\x80\x9CBayes\xE2\x80\x99 Theorem\xE2\x80\x9D, <i>The Stanford Encyclopedia of Philosophy</i> (Fall 2003 Edition), Edward N. Zalta (<i>ed</i>.), URL = http://plato.stanford.edu/entries/bayes-theorem/</p>  <p class=\"cit\">Maher, P., 1993, <i>Betting on Theories</i>. Cambridge: Cambridge University Press.</p>  <p class=\"cit\">Milne, P., 1996, \xE2\x80\x9CLog[<i>p</i>(<i>h/eb</i>)<i>/p</i>(<i>h/b</i>)] is the one true measure of confirmation,\xE2\x80\x9D <i>Philosophy of Science</i> 63: 21\xE2\x80\x9326.</p>  <p class=\"cit\">Popper, K., 1957, \xE2\x80\x9CThe propensity interpretation of the calculus of probability, and the Quantum Theory,\xE2\x80\x9D in S. K\xC3\xB6rner (<i>ed</i>.): <i>Observation and Interpretation in the Philosophy of Physics</i>.</p>  <p class=\"cit\">Rosenkrantz, R., 1977, <i>Inference, Method and Decision</i>. Dordrecht: D. Reidel.</p>  <p class=\"cit\">Royall, R., 1997, <i>Statistical Evidence: A Likelihood Paradigm</i>. London: Chapman &amp; Hall.</p>  <p class=\"cit\">Schick, F., 1986, \xE2\x80\x9CDutch Bookies and Money Pumps,\xE2\x80\x9D <i>Journal of Philosophy</i> 83: 112\xE2\x80\x93119.</p>  <p class=\"cit\">Sober, E., 2003, \xE2\x80\x9CLikelihood and the Duhem/Quine Problem,\xE2\x80\x9D unpublished manuscript.</p>"
reviewer: Branden Fitelson , University of California'Berkeley
review_title: Bayes's Theorem
