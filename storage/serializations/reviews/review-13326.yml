--- 
catalog_id: 2008.06.13
review_id: 13326
images: []

bibliography: Eric Christian Barnes, <em>The Paradox of Predictivism</em>, Cambridge University Press, 2008, 265pp., $99.00 (hbk), ISBN 9780521879620.<br />
links: []

content: |-
  <p>&quot;Predictivism&quot; has to do with the trust or credence one places in hypotheses. The question is usually put as to whether hypotheses only gain support from &quot;novel&quot; predictions, or whether a hypothesis that predicts a novel phenomenon thereby gains more support than a hypothesis that can accommodate the phenomenon, for example by assignment of particular values to otherwise free parameters or by citing special conditions.</p>  
  <p>Barnes&#39; book puts a novel twist on the issue by placing it in a context in which predictions are made by people who endorse hypotheses, and we, the evaluators of the hypotheses, may, indeed should, take account of the significance of those endorsements -- or their absences -- in our assessment of hypotheses. Barnes&#39; central idea is that such considerations both provide a rational ground for giving more weight to hypotheses when they have been used for novel predictions than when they have been used to accommodate the data, post-hoc, and also explain why we are inclined to do so. The first of these theses is normative, the second psychological. Part of the argument for the normative thesis is clever and original and bears reflection; a smaller part of it is not. The argument for the psychological case rests on a single historical case, and I think it needs more scholarship to be convincing. Barnes puts his account to work on a variety of philosophical issues: belief in the truth of successful theories (realism) as against various sorts of anti-realism; community predictions; the problem of old evidence, etc. I will focus on what I take to be the main argument.</p>  
  <p>We consider two theorists, P and A, a &quot;randomly generated&quot; theory T, observed data O available to both, and an evaluator E, who has some not too high prior probability P(T | O). P assigns sufficiently high probability Pp(T | O) to qualify as an endorsement of T. A does not. From T, P predicts N, which comes to be true. After observing N, A&#39;s probability for T also increases; although it is not always assumed that Pa(T | O, N) = Pp(T | O, N). The question Barnes poses concerns E&#39;s inference in two scenarios, one in which she is informed about P&#39;s probabilities, the other in which she is informed about A&#39;s probabilities. Call them scenarios P and A.</p>  
  <p>Barnes argues that before learning about the truth or falsity of N, on the assumption that everyone is perfectly rational and computes their conditional probabilities appropriately, E should give higher probability to T in scenario P than in scenario A. The argument is this:</p>  <p style="margin-left: 0.5in">Because competent scientists do not endorse theories on the basis of insufficient evidence (Howson 1988, 382) Eva may judge that reason(s) R exists [for P&#39;s endorsement] though she does not know what R is . . . Eva can now judge that T is supported [in the P scenario] . . . by R as well. (p. 10, Chapter 3)</p>  
  <p>I find this argument rather worse than unconvincing. If &quot;rational&quot; and &quot;competent&quot; means subjective Bayesian, then the conclusion does not follow at all. P may simply have a higher subjective probability Pp(T | O) for T conditional on O than does A. The citation of Howson is bewildering. If it is an appeal to authority, the authority is insufficient. If it is an endorsement of an historical generalization, it is absurd unless most of the scientists in history are &quot;incompetent&quot;: the history of science is a history of endorsements on what seem, in retrospect, insufficient evidence. If it is a revelation of Barnes&#39; own definition of &quot;competent&quot; then the argument seems a trivial tautology.</p>  
  <p>Section 3.4 considers the posteriors for E in the two scenarios after the observation of N. Barnes considers a case in which the likelihood of N given T is the same for P and A, and a case in which the posteriors for T given N (and O) are the same for P and A, and assumes that the difference in their assessments is due to different prior knowledge sets for P and A. The premises here are more explicit and the argument much more convincing, although I am sure it will be debated by others. I pass to Barnes&#39; historical remarks.</p>  
  <p>The explanatory case concerns the acceptance of Mendellev&#39;s periodic table. Barnes reviews conflicting accounts by Brush, on the one hand, and by Scerri and Worrall on the other. (Brush is a distinguished and very competent historian; Scerri is surely the most accomplished philosopher writing chiefly about chemistry; Worrall is a prominent philosopher of science.) Brush argues that textbooks in the late 19<sup>th</sup> century cited Mendellev&#39;s table more frequently as his predictions of the properties of new elements were confirmed. Scerri and Worrall point out that the Davy Medal citation for Mendellev does not mention the successful predictions, and that many of the textbook citations of Mendellev&#39;s theory noted by Brush do not mention the predictions. Barnes simply dismisses this argument as a &quot;classic fallacy of social science&quot; that &quot;members of a community are doing . . . what members say (or fail to say) they are doing.&quot; &quot;There is no reason to think that the Davy Medal citation or the textbooks that discuss [Mendel&#39;s periodicity theory] would mention the successful predictions even if these predictions were the most important evidence in favor . . .&quot; (p. 32, Chapter 3).</p>  
  <p>Barnes&#39; argument here seems to me, well, glib, despite his detailed use of the secondary literature. He might have made a more serious case by examining other Davy Medal citations in cases where novel predictions were the warrant -- or, less relevantly, Nobel citations; he might have considered whether the textbooks in question considered the evidence for or against other hypotheses, in however textbooky a fashion. Of course, Barnes does not pretend to do original history -- but if the major basis for his claim that his account of predictivism explains aspects of scientific judgment rests on this single case, and the case is reasonably controverted, he seems obliged to find better evidence than a conjecture. And I regret the attempt to rest a psychological case upon an analysis of a single historical episode. What is wrong with philosophers who have an explanatory thesis about practical reasoning proposing -- even carrying out -- psychological experiments to test it?</p>  
  <p>These criticisms aside, there is no question that our assessments of theories has a great deal to do, rationally or not, with our assessments of others who endorse or reject them. I think a great deal of that is sheer crowd following, but Barnes breaks new ground in trying to figure out how and when it could be rational.</p>
authors: Eric Christian Barnes
transformed_content: |-
  <p>&quot;Predictivism&quot; has to do with the trust or credence one places in hypotheses. The question is usually put as to whether hypotheses only gain support from &quot;novel&quot; predictions, or whether a hypothesis that predicts a novel phenomenon thereby gains more support than a hypothesis that can accommodate the phenomenon, for example by assignment of particular values to otherwise free parameters or by citing special conditions.</p>  
  <p>Barnes&#39; book puts a novel twist on the issue by placing it in a context in which predictions are made by people who endorse hypotheses, and we, the evaluators of the hypotheses, may, indeed should, take account of the significance of those endorsements -- or their absences -- in our assessment of hypotheses. Barnes&#39; central idea is that such considerations both provide a rational ground for giving more weight to hypotheses when they have been used for novel predictions than when they have been used to accommodate the data, post-hoc, and also explain why we are inclined to do so. The first of these theses is normative, the second psychological. Part of the argument for the normative thesis is clever and original and bears reflection; a smaller part of it is not. The argument for the psychological case rests on a single historical case, and I think it needs more scholarship to be convincing. Barnes puts his account to work on a variety of philosophical issues: belief in the truth of successful theories (realism) as against various sorts of anti-realism; community predictions; the problem of old evidence, etc. I will focus on what I take to be the main argument.</p>  
  <p>We consider two theorists, P and A, a &quot;randomly generated&quot; theory T, observed data O available to both, and an evaluator E, who has some not too high prior probability P(T | O). P assigns sufficiently high probability Pp(T | O) to qualify as an endorsement of T. A does not. From T, P predicts N, which comes to be true. After observing N, A&#39;s probability for T also increases; although it is not always assumed that Pa(T | O, N) = Pp(T | O, N). The question Barnes poses concerns E&#39;s inference in two scenarios, one in which she is informed about P&#39;s probabilities, the other in which she is informed about A&#39;s probabilities. Call them scenarios P and A.</p>  
  <p>Barnes argues that before learning about the truth or falsity of N, on the assumption that everyone is perfectly rational and computes their conditional probabilities appropriately, E should give higher probability to T in scenario P than in scenario A. The argument is this:</p>  <p style="margin-left: 0.5in">Because competent scientists do not endorse theories on the basis of insufficient evidence (Howson 1988, 382) Eva may judge that reason(s) R exists [for P&#39;s endorsement] though she does not know what R is . . . Eva can now judge that T is supported [in the P scenario] . . . by R as well. (p. 10, Chapter 3)</p>  
  <p>I find this argument rather worse than unconvincing. If &quot;rational&quot; and &quot;competent&quot; means subjective Bayesian, then the conclusion does not follow at all. P may simply have a higher subjective probability Pp(T | O) for T conditional on O than does A. The citation of Howson is bewildering. If it is an appeal to authority, the authority is insufficient. If it is an endorsement of an historical generalization, it is absurd unless most of the scientists in history are &quot;incompetent&quot;: the history of science is a history of endorsements on what seem, in retrospect, insufficient evidence. If it is a revelation of Barnes&#39; own definition of &quot;competent&quot; then the argument seems a trivial tautology.</p>  
  <p>Section 3.4 considers the posteriors for E in the two scenarios after the observation of N. Barnes considers a case in which the likelihood of N given T is the same for P and A, and a case in which the posteriors for T given N (and O) are the same for P and A, and assumes that the difference in their assessments is due to different prior knowledge sets for P and A. The premises here are more explicit and the argument much more convincing, although I am sure it will be debated by others. I pass to Barnes&#39; historical remarks.</p>  
  <p>The explanatory case concerns the acceptance of Mendellev&#39;s periodic table. Barnes reviews conflicting accounts by Brush, on the one hand, and by Scerri and Worrall on the other. (Brush is a distinguished and very competent historian; Scerri is surely the most accomplished philosopher writing chiefly about chemistry; Worrall is a prominent philosopher of science.) Brush argues that textbooks in the late 19<sup>th</sup> century cited Mendellev&#39;s table more frequently as his predictions of the properties of new elements were confirmed. Scerri and Worrall point out that the Davy Medal citation for Mendellev does not mention the successful predictions, and that many of the textbook citations of Mendellev&#39;s theory noted by Brush do not mention the predictions. Barnes simply dismisses this argument as a &quot;classic fallacy of social science&quot; that &quot;members of a community are doing . . . what members say (or fail to say) they are doing.&quot; &quot;There is no reason to think that the Davy Medal citation or the textbooks that discuss [Mendel&#39;s periodicity theory] would mention the successful predictions even if these predictions were the most important evidence in favor . . .&quot; (p. 32, Chapter 3).</p>  
  <p>Barnes&#39; argument here seems to me, well, glib, despite his detailed use of the secondary literature. He might have made a more serious case by examining other Davy Medal citations in cases where novel predictions were the warrant -- or, less relevantly, Nobel citations; he might have considered whether the textbooks in question considered the evidence for or against other hypotheses, in however textbooky a fashion. Of course, Barnes does not pretend to do original history -- but if the major basis for his claim that his account of predictivism explains aspects of scientific judgment rests on this single case, and the case is reasonably controverted, he seems obliged to find better evidence than a conjecture. And I regret the attempt to rest a psychological case upon an analysis of a single historical episode. What is wrong with philosophers who have an explanatory thesis about practical reasoning proposing -- even carrying out -- psychological experiments to test it?</p>  
  <p>These criticisms aside, there is no question that our assessments of theories has a great deal to do, rationally or not, with our assessments of others who endorse or reject them. I think a great deal of that is sheer crowd following, but Barnes breaks new ground in trying to figure out how and when it could be rational.</p>
reviewer: Clark Glymour, Carnegie Mellon
review_title: The Paradox of Predictivism
