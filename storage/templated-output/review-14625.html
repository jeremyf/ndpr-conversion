
















<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Douglas Walton - Witness Testimony Evidence: Argumentation, Artificial Intelligence, and Law - Michael S. Pardo, University of Alabama - Philosophical Reviews - University of Notre Dame</title>
<link rel="stylesheet" type="text/css" href="css/global.css" title="Default Style" />
<link rel="stylesheet" type="text/css" media="print" href="css/print.css" />
<link rel="alternate stylesheet" type="text/css" media="screen" href="css/nostyle.css" title="No Style" />
<script type="text/javascript" src="js/styles.js"></script>
</head>
<body id="reviews">
<div id="wrapper">
  <div id="header">
    <a href="./" id="prhome">Philosophy Reviews</a>
    <ul id="menu">
      <li><a href="reviews.cfm" id="rev">Reviews</a></li>
      <li><a href="board.cfm" id="edi">Editorial Board</a></li>
      <li><a href="guidelines.cfm" id="gui">Reviewers Guidelines</a></li>
      <li><a href="http://listserv.nd.edu/cgi-bin/wa?SUBED1=philosophical-reviews&A=1" id="sub">Subscribe</a></li>
    </ul>
    <form action="search.cfm" method="get" id="search" title="Search Form">
      Search
        <select name="type">
          <option value="author">Author</option>
          <option value="title">Title</option>
          <option value="reviewer">Reviewer</option>
          <option value="keyword">Keyword</option>
        </select>
for
<input name="q" type="text" size="16" />
<input type="submit" name="Submit" value="Go" class="submit" />
    </form>
  </div>
  <div id="content">
    <div id="review"><h1>2008.11.06</h1>
    <h4>Douglas Walton</h4>
  <h2>Witness Testimony Evidence: Argumentation, Artificial Intelligence, and Law</h2>

  <p class="biblio">Douglas Walton, <em>Witness Testimony Evidence: Argumentation, Artificial Intelligence, and Law</em>, Cambridge University Press, 2008, 365pp., $29.99 (pbk), ISBN 9780521707701.<br /></p>
  <p><strong>Reviewed by Michael S. Pardo, University of Alabama</strong></p>
    <div id="hr"><hr /></div>

<p>Understanding the epistemology of witness testimony is tremendously important for the law. In any legal order, a significant degree of factual accuracy is a necessary condition for just legal judgments, and witness testimony (whether in oral or written form) provides a major -- indeed, often the most important -- class of evidence on which such judgments depend. For these reasons, evidence scholars in law devote attention to the epistemology of the legal proof in general and the role of testimony in particular. A major theme of this scholarly focus has been the extent to which aspects of the proof process can and ought to be formalized. The attempts at formalization typically have appealed to probability theory, often presenting Bayesian models of (1) the proof structure as a whole, (2) aspects of it such as burdens of proof and decision standards, or (3) the probative value of masses or individual items of evidence. Although these models have contributed greatly to understanding some aspects of juridical proof, they have been shown to suffer from deep problems from descriptive, explanatory, analytical, and normative perspectives. Given these limitations, interests have shifted toward other theoretical ways to understand the process and other ways to model it.</p>  
<p>Douglas Walton&#39;s book, <em>Witness Testimony Evidence</em>, is an example of this trend. Focusing primarily on the Anglo-American trial system, the book looks to logic, argumentation theory, formal dialectical models, and artificial intelligence to &quot;understand the structure of witness testimony as a form of evidence in law&quot; (1). It analyzes and evaluates this structure with the aid of formal systems that diagram the inferential relationships between testimonial assertions and the conclusions they are intended to support (in this sense, they are computerized methods similar to one developed in the early Twentieth Century by the great evidence scholar John Henry Wigmore). Although the book discusses the common epistemic problems that can arise with witness testimony, it ultimately defends the trial&#39;s reliance on this form of evidence as rational and justified.</p>  
<p>The book provides a synoptic discussion of possible ways in which the formal tools may help to analyze and evaluate witness testimony, rather than focusing on the details of one particular model. It thus provides an excellent introduction to evidence for scholars otherwise unfamiliar with the formal tools. It also provides a useful overview of the philosophical and legal issues that underlie such models, and may thus serve as a foundational text for future work developing the formal methods. Finally, the book will be of interest not only to evidence scholars, those interested in the formal modeling of argumentation, and others interested in the particularities of legal proof. Those interested in the epistemology of testimony more generally will find that many of the issues, examples, analyses, and arguments have broader philosophical significance and applications beyond the law.</p>  
<p>The book succeeds in its aims of providing an overview of the field and illuminating the general structure of testimonial evidence in law. It also provides insightful analysis of numerous examples. The normative and evaluative aspects of the book&#39;s analysis, however, are much less developed than the descriptive aspects. Moreover, given the early stages of the models and systems discussed, the book provides more of a sense of the ways in which the analysis and models may contribute in the future, rather than a discussion of how they can currently improve legal decision making.<strong><em> </em></strong>This review summarizes the book&#39;s seven chapters and then concludes with some brief observations about possible contributions and limitations of the formal analysis toward understanding, and perhaps improving, juridical proof.</p>  
<p>Walton constructs an overarching dialectical model to analyze and evaluate appeals to witness testimony within the structure of legal proof. Rejecting deductive and probabilistic inductive models, the book presents a model characterized by defeasible, plausibilistic (&quot;eikotic&quot;) reasoning. The conclusions of this reasoning are defeasible in the sense that &quot;they only hold tentatively and are subject to defeat . . . as new evidence comes in&quot; (5); the arguments function &quot;to shift a weight of presumption&quot; (32). Moreover, the structure of legal proof involves a comparative assessment by the jury of the plausibility of the accounts of the disputed events put forward by each side. Within this structure, appeals to witness testimony are used to provide information that either supports or attacks these accounts.</p>  
<p>Chapter One provides an argumentation scheme that illustrates how testimony functions as legal evidence. According to this scheme, appeals to witness testimony are presented as arguments of the following form:</p>  <p style="margin-left: 0.5in">1. Witness W is in a position to know whether proposition A is true or not.</p>  <p style="margin-left: 0.5in">2. Witness W is telling the truth (as W knows it).</p>  <p style="margin-left: 0.5in">3. Witness W states that A is true (false).</p>  <p style="margin-left: 0.5in">4. Therefore (defeasibly) A is true (false).</p>  
<p>The structure of the argument is one of defeasible <em>modus ponens</em>. Given the premises, the conclusion holds unless and until the opponent counters with a move that defeats the conclusion, either by challenging a premise or providing an exception to the rule that links the premises and the conclusion. These counter moves typically involve critical questioning of witnesses designed to show problems with the testimony -- such as its internal inconsistency, its inconsistency with known facts, its inconsistency with other testimony or other evidence, witness untrustworthiness or bias, and so on. These moves and counter-moves take place within the larger context of each side attempting to support its version of events and attack the version put forward by the other side.</p>  
<p>Chapters Two and Three discuss this larger context in more detail. Appeals to witness testimony take place in a context characterized by plausibility, rather than probability, assessments. A major difference is that plausibilistic, unlike probabilistic,<strong><em> </em></strong>reasoning rejects the rule of negation, in which the probability of a proposition and its negation must equal 1 -- the parties at trial may advance contradictory theories each of which is highly plausible. The key task for legal decision-makers<strong><em> </em></strong>is to assess the relative plausibility of these accounts. This assessment proceeds abductively; jurors infer the best explanation of the events and evidence in dispute. In assessing the plausibility of these accounts, jurors fill in gaps in parties&#39; accounts through Gricean implicature, scripts, and &quot;anchored narratives&quot; (stories constructed from inferences based on commonsense generalizations about what happens in similar situations). Parties use appeals to witness testimony to bolster or attack the plausibility of the competing accounts.</p>  
<p>In Chapter Four, entitled &quot;Computational Dialectics,&quot; Walton turns to &quot;formal systems of dialogue&quot; and argumentation theory in order to further analyze and evaluate appeals to witness testimony within law (151-52). Concepts from these fields are used to construct a normative model or &quot;theoretical device that . . . specifies requirements and standards that an argument (or other moves in dialogue, such as the asking of a question) should meet if it is to be considered structurally correct&quot; (152). After surveying different types of dialogues, and speech acts within dialogues, Walton labels the trial a &quot;persuasion dialogue&quot; with the goal of resolving or clarifying issues, with participants aiming to prove or disprove a thesis (159). Within this larger dialogue, witness testimony comprises nested dialogues labeled &quot;information seeking&quot; with the goal of acquiring or giving information (159). The rest of the book is devoted to exploring possible ways in which attempts to formalize these types of dialogues -- in argumentation theory, artificial intelligence, and other fields -- may yield insights into legal testimony.</p>  
<p>Chapters Five and Six explore the details of testimony as an information-seeking dialogue embedded within the persuasion dialogue of the trial. Information is defined as &quot;reduction of uncertainty in the sense of inference to the best account of an event by filling in and assessing the account of the event&quot; (209). Witness examination occurs on two levels. The first is getting information from the witness. The second is the &quot;peirastic level,&quot; which has the &quot;function of testing out the answers of the witness&quot; (240). The periastic level involves testing the plausibility of the testimony against other testimony, other evidence, or known facts, as well as information about the witness&#39;s trustworthiness or possible bias. These dialogues are relevant to the extent they contribute to the overall persuasion dialogue of the trial. Walton uses this model to explain several aspects of the trial including legal relevance, leading questions on cross-examination, and expert testimony.</p>  
<p>Chapter Seven concludes by exploring possibilities for formalizing the analysis and evaluation of witness testimony. Walton sketches how different computer systems (Carneades, DefLog, Araucaria) may diagram the inferential relationships between testimonial assertions and the ultimate conclusions at issue in a legal dispute. The discussion appears designed more to give a flavor of the possibilities rather than to present a full-fledged model. The book also discusses problems with these extant models. For example, one problem includes how to model questions intended to defeat an appeal to witness testimony. Should the questions be treated as explicit premises? Should the questions by themselves ever defeat or undercut testimony? The proposed solution draws distinctions based on the nature of the questions. Some questions (&quot;exceptions&quot;) -- e.g., those that claim or imply inconsistency with other testimony, evidence, or known facts -- do not defeat witness testimony until the questioner provides reasons or evidence showing the claimed inconsistency (313-14). Other questions (&quot;antecedents&quot; or &quot;assumptions&quot;) -- e.g., those that challenge trustworthiness -- defeat testimony unless the proponent of the testimony responds with further arguments or evidence (313-14). Within the formalization process, which category the question falls into would then determine how the computer program models the testimony, which may then be used to evaluate whether the conclusions based on the testimony ought to be accepted or rejected.</p>  
<p>Formal analysis of the kind Walton sketches may contribute to the epistemology of legal proof on two different levels. It might provide micro-level insights regarding the strength or weakness of particular items or combinations of testimony. It might also provide macro-level insights regarding when and whether testimonial evidence is sufficient to satisfy a burden of proof and decision standard (typically proof &quot;by a preponderance of the evidence&quot; in civil cases and &quot;beyond a reasonable doubt&quot; in criminal cases). The book provides many micro-level insights. For example, Walton provides a useful analysis of &quot;linked&quot; versus &quot;convergent&quot; arguments based on legal evidence (80-82). In a linked argument, each premise is necessary to support the conclusion. By contrast, in a convergent argument the premises provide independent support for the conclusion. In assessing the plausibility of a conclusion, it helps to examine which type of argument is being made. If it is linked, then the plausibility of the conclusion will be at least as strong as the plausibility of the weakest premise. If it is convergent, then the plausibility of the conclusion will be at least as strong as the plausibility of the strongest premise. Walton&#39;s analysis of issues such as this will both solidify and help to make explicit the intuitions of many evidence scholars.</p>  
<p>One limitation of the book, however, is that it does not provide much insight into macro-level determinations regarding the sufficiency of testimonial evidence. Any normative evaluation of whether witness testimony is sufficient to support a legal judgment depends on an account of the probative value of the evidence in relation to the applicable decision standard, which specifies the required level of proof. The decision standards serve the important functions of minimizing adjudicative errors and allocating the risk of errors among the parties (for example, against the government and in favor of defendants in criminal cases). The book does not do much to connect the analysis and evaluation of testimony to these important macro-level issues; therefore, despite any micro-level evaluations the formal analysis may provide, the analysis provides little normative guidance about how particular cases ought to be decided.</p>  
<p>This limitation suggests a deeper, more general limitation on formal analysis of witness testimony. Much of the evidence used to decide legal disputes resides in the minds of jurors and judges; it is not just what is admitted into court. The inferences at trial, in other words, involve the interaction of the evidence and arguments of the parties with the knowledge of the individuals deciding the cases. How the latter could be modeled formally is not clear, at least to this reviewer. Consider just one example: juror assessments of witness testimony often involve not only interpretations of witness utterances but also interpretations of witness demeanor and what it may imply, each of which will be affected by the background beliefs and knowledge of the individual decision-makers. Any model of testimony that purports to offer normative guidance will have to somehow model this background knowledge. A failure to do so limits the value of the models for law. It is too soon to tell the extent to which the models Walton discusses will succeed in formalizing aspects of legal proof. This deeper limitation suggests, however, that, like those based on probability theory, the models may provide useful heuristics for understanding some aspects of the process, but they will not eliminate the need for the wise exercise of discretion and judgment by human decision-makers in evaluating evidence.</p>

  </div></div>

<div id="footer">
    <p>Copyright &copy; 2004 Notre Dame Philosophical Reviews<br />
  Site Last Modified: 3/8/2011  <br>
ISSN: 1538 - 1617</p>
    <p><a href="http://www.nd.edu/" id="ndhome">University of Notre Dame </a></p>
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-344381-6";
urchinTracker();
</script>
</div>

</div>
</body>
</html>
