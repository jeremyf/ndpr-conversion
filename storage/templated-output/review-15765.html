
















<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>John Forge - The Responsible Scientist: A Philosophical Inquiry - Michael Arribas-Ayllon, Cardiff University, and Kristrún Gunnarsdóttir, Cardiff University - Philosophical Reviews - University of Notre Dame</title>
<link rel="stylesheet" type="text/css" href="css/global.css" title="Default Style" />
<link rel="stylesheet" type="text/css" media="print" href="css/print.css" />
<link rel="alternate stylesheet" type="text/css" media="screen" href="css/nostyle.css" title="No Style" />
<script type="text/javascript" src="js/styles.js"></script>
</head>
<body id="reviews">
<div id="wrapper">
  <div id="header">
    <a href="./" id="prhome">Philosophy Reviews</a>
    <ul id="menu">
      <li><a href="reviews.cfm" id="rev">Reviews</a></li>
      <li><a href="board.cfm" id="edi">Editorial Board</a></li>
      <li><a href="guidelines.cfm" id="gui">Reviewers Guidelines</a></li>
      <li><a href="http://listserv.nd.edu/cgi-bin/wa?SUBED1=philosophical-reviews&A=1" id="sub">Subscribe</a></li>
    </ul>
    <form action="search.cfm" method="get" id="search" title="Search Form">
      Search
        <select name="type">
          <option value="author">Author</option>
          <option value="title">Title</option>
          <option value="reviewer">Reviewer</option>
          <option value="keyword">Keyword</option>
        </select>
for
<input name="q" type="text" size="16" />
<input type="submit" name="Submit" value="Go" class="submit" />
    </form>
  </div>
  <div id="content">
    <div id="review"><h1>2009.04.03</h1>
    <h4>John Forge</h4>
  <h2>The Responsible Scientist: A Philosophical Inquiry</h2>

  <p class="biblio">John Forge, <em>The Responsible Scientist: A Philosophical Inquiry</em>, University of Pittsburgh Press, 2008, 272pp., $39.95 (hbk), ISBN 9780822043495.<br /></p>
  <p><strong>Reviewed by Michael Arribas-Ayllon, Cardiff University, and Kristrún Gunnarsdóttir, Cardiff University</strong></p>
    <div id="hr"><hr /></div>

<p>Can we hold scientists responsible for unintended outcomes? Are they duty-bound to consider what future possibilities lie in their research? <em>The Responsible Scientist</em> will not disappoint the moralist seeking a detailed and well thought-out system with which to hold scientists responsible. Indeed, there appears to be growing demand for a book of this kind. Controversies surrounding weapons research, molecular biology, nanotechnology and physics have, in recent years, attracted attention from philosophers, ethicists, sociologists, and anthropologists. John Forge combines rigorous ethical argument with an in-depth knowledge of modern scientific practice, though we suspect this book will appeal mainly to philosophers of science and concerned scientists.</p>  
<p>There are two aspects of the book that make it more readable than the title suggests: the originality with which the concept of responsibility is developed and the examples and case studies to which it is applied. The central argument is that the implications of scientific work are such that we need a broader account of responsibility that includes not only what scientists intend (the &#39;standard&#39; view of responsibility), but also the <em>foreseen</em> and <em>foreseeable</em> outcomes of their research. The main strength of this argument, and the book overall, lies in the many examples that Forge uses to illustrate the conditions of responsibility in research contexts: from personal observations of university research teams to detailed case studies of historical events that have profoundly shaped the way scientific research is conducted today.</p>  
<p>The structure of the book reflects the author&#39;s central claim that responsibilities can be temporally distinguished in terms of &#39;forward looking&#39; and &#39;backward looking&#39; responsibility. The latter is the common form, whereby matters of responsibility arise after an event occurs. But the former defines &#39;special responsibilities&#39; for research outcomes that are transformative and future-oriented. The argument is<em> </em>set out in four parts: on the responsibility of outcomes (Part 1), looking back (Part 2), looking forward (Part 3), and group/collective responsibility in contemporary scientific research (Part 4).</p>  
<p>Forge begins by arguing that we cannot impute different sorts of responsibilities on the basis of a distinction between &#39;pure&#39; or &#39;applied&#39; research. It is not the content of these activities that defines their difference, but the context in which scientific projects -- concerned with ideas <em>and </em>technologies -- are conducted. The argument that the discovery of true propositions is <em>always</em> good, even if the outcomes are potentially harmful, is flawed. The burden of responsibility lies not with a society to negotiate the mixed blessing of science but with the scientist&#39;s <em>intention</em> to discover. Scientists cannot be excused from responsibility on the grounds of neutrality because scientific work is subjective and value-laden. For example, the events preceding the Manhattan Project illustrate that the responsibility of scientists (e.g. Rudolf Peierls&#39; contribution to implosion design for fissionable uranium 235) has<strong> </strong>both factual and normative dimensions. Forge takes issue with the standard view of responsibility because it provides the scientist with the blanket excuse that he<strong> </strong>cannot be held responsible for what he had not intended. What Forge calls the &#39;modified standard view&#39; offers a revaluation of action theory and intention by arguing that an agent&#39;s intentional actions support inferences about what he or she <em>prefers</em>. Research outcomes, he says, &#39;belong&#39; to an agent or an agent has &#39;control&#39; over an outcome for which he is responsible.</p>  
<p>So if the modified view attaches responsibility to <em>all</em> actions that the agent foresees (because all of them are now undertaken intentionally) what do we make of the disinterested scientist for whom such preferences have not entered her deliberations? It is tempting to suggest that there is something defective or blameworthy about their &#39;character&#39;. In chapter 6, Forge presses the point that ignorance is not a suitable excuse. Science, as a social and institutional practice, is bound by certain rules. The proposition &#39;science affects people&#39; (SAP) is introduced as one such rule whereby scientists are expected to know that research outcomes affect the greater public. Scientists cannot ignore SAP for the boundaries between academic, industrial and government research are increasingly blurred. The increased mobility of scientists and their dependence on grants (containing beneficent mission statements) also suggests that scientists know SAP. But ignorance, like &#39;omissions&#39;, are less transparent than actions. Being responsible for omissions rests upon the assumption that one did know whereas if one did not know, she supposedly is not responsible. Using the framework of SAP, however, Forge emphasizes the duty to seek out opportunities to do good as well as to ensure against doing harm (the position-to-know test). This superordinate principle presupposes a &#39;common morality&#39; which forms the basis of an ethics of science.</p>  
<p>The position-to-know test and the normative dimension of science are explored further in chapters 7 and 8. Forge rejects Michael Polanyi&#39;s defense of the &#39;double unpredictability&#39; of scientific practice, i.e. if scientific findings and the outcomes issuing from them are unpredictable then outcomes cannot be foreseen. Forge illustrates how the first part of Polanyi&#39;s claim -- that scientific <em>findings</em> are unpredictable -- is false. Scientific procedures rely on the predictability of properties such as of nuclei, atoms, compounds, viruses, etc. Even Thomas Kuhn would testify to scientists&#39; <em>expectations</em> that their findings will accord with a paradigm. The most plausible example is found in patent applications. The criteria of successful patent applications rely on scientists foreseeing future applications. The lessons from history of science and technology, however, address the other part of Polanyi&#39;s claim: that scientific <em>outcomes</em> are inherently unpredictable. In cases of &#39;genuine innovation&#39; (such as the convergence of several streams of scientific and technological activity) it would appear that outcomes are unpredictable. What Forge concludes is that scientists can be expected to see where their research will lead <em>sometimes</em> but not always.</p>  
<p>In the book&#39;s third part, Forge argues that a forward-looking responsibility (an ethics of science) is justified in terms of Bernard Gert&#39;s &#39;common morality&#39;. Scientists are &#39;required not to do wrong by causing harm and are encouraged to do good by preventing it&#39; (p. 148). Forge applies this two-tier system of responsibility to weapons research, a case that reveals the author&#39;s strongest sentiments. He argues that weapons researchers provide the means, either directly or indirectly, to do future harm. Weapons research might seem to be justified on historical grounds or excused on ahistorical grounds, but as Forge shows: &#39;there is no ahistorical or context-free excuse or justification for weapons<strong> </strong>research&#39; (p. 162). So what should scientists do? Here, Forge focuses on the positive duties to prevent harm. Scientists are in a position not only to solve problems but to point out that they exist. The scope of scientists&#39; positive duties is<strong> </strong>&#39;narrow&#39; in the sense that they are confined to the special skills that characterize their expertise; the rest is left to politics. Forge recommends a focus on &#39;global&#39; problems, matters affecting health and food production, and so on. But we are left wondering whether the scientist is truly in a position, in his or her local and situated work, to reflect upon, and devise responsible decisions in relation to, such &#39;external&#39; matters.</p>  
<p>Given that scientific research is increasingly collaborative and interdisciplinary, it seems fitting that Forge dedicates the final part of his book to group/collective responsibility. The task is to establish a genuine group responsibility that does not excuse the individual scientist from responsibility. One approach infers a relationship of dependency between individuals and groups without reducing the latter to the former. Group responsibility must <em>supervene</em> on human action where individual actions share the same set of properties as group actions. One way of understanding this relationship is in terms of <em>vicarious liability</em>, an obvious example being the principal-agent relation where responsibility is transferred via &#39;substituted decision-making&#39;. An autonomous, moral agent acts in accordance with the values or imperatives of a corporation (e.g. the maximization of profit). Is the agent therefore excused for his actions while a member of that corporation? Not entirely, because the agent is still <em>acting</em>, albeit, in a role on behalf of another. This approach helps to distinguish collective responsibility from shared responsibility. In the latter, decisions and choices &#39;belong&#39; to each of the members, not to something or someone else. This leads Forge to conclude that collectives seem more like collections of &#39;roles&#39; rather than classes of individuals. But the role performance of an individual in a corporation does involve a degree of volition and choice &ndash; the individual in a corporation has chosen more or less freely to take on a role. This does not remove responsibility from the individual, but &#39;it does mitigate blame, to a degree&#39; (p. 214).</p>  
<p>So can we attribute either shared or collective responsibility to groups of scientists? Scientific research is characterized by different kinds of groups. Scientists often fail to satisfy the position-to-know test and show few instances of substituted decision-making. Projects are typically short-lived or lack formal structures in terms of predefined roles, decision-making mechanisms, policies and procedures. Regarding his own observations, Forge concludes that collective responsibility cannot be attributed to groups of scientists. Rather, he observes shared responsibility with varying degrees of control by principal investigators. But there are a few research institutes that approximate mature organization and exhibit collective (corporate) responsibilities, e.g. the Salk Institute and the Sloan Kettering Foundation in the US, and the Max Planck Institutes in Germany. So, is Forge left to narrow his treatment of responsible scientists to agents working in mature organizational settings?</p>  
<p>Despite making some strong claims throughout the book, Forge resorts to rather soft conclusions: &#39;not only is the scientist responsible for what he intends to do, and what he foresees that he does, but he <em>may</em> also be responsible for actions and outcomes that he does not foresee&#39; (p. 223, our emphasis). What appears to mitigate responsibility for unforeseen outcomes is the context and institutional arrangement in which scientific research is actually conducted. Indeed, there appear<strong> </strong>to be legitimate circumstances that are beyond the control of solitary individuals. And what about the scientist who takes up employment in a government or corporate industrial lab? Does she not have a responsibility to her employer? Borrowing a term from medical ethics, Forge argues that she has &#39;dual loyalties&#39;, to be a good employee and a good citizen. Taking responsibilities seriously, the title of the concluding chapter, is &#39;a matter of <em>intending</em> to do research that does not issue in harmful outcomes and also, one would hope, <em>intending</em> to do research that has good outcomes&#39; (p. 233).</p>  
<p>Forge has undertaken an ambitious inquiry. His philosophical arguments are elegantly and rigorously formulated, the potential dryness of which is compensated for by lively writing and sophisticated examples. However, we have a number of reservations. Our first concern is the conception of the subject (&#39;the scientist&#39;), which underpins Forge&#39;s entire system of responsibility. Intentionality is not a concept that can be easily dismissed because there are occasions when the scientist&#39;s actions are so conspicuous and his deeds so despicable that we may want to impute intentions as the basis for attributing blame. But <span>we find the whole edifice of action theory troubling because it gives the philosopher a license to impute psychological processes. The scientist is responsible for outcome X because, in some deliberative sense, he or she preferred and was motivated to act in one way and not another. Forge confers internal attributes to isolated individuals -- not groups, collectives or networks -- as the means to blame or praise. He admits that perhaps neurologists are in a better position to impute motivations, but this does not stop the philosopher from reconstructing the &#39;facts&#39; of what an agent did in order to locate intentions. It has, after all, a strategic purpose -- to prescribe the conduct of scientists.</span></p>  
<p>Another concern we have is whether the project of this book gives a rich enough account of scientific practice. This is not so much a criticism of the author&#39;s work but of this particular discipline of philosophical inquiry. Forge&#39;s detailed arguments &#39;work&#39; when intentional actors are isolated from their context and scrutinized independently of the constraints that subsist in local situations. This is especially the case when philosophical thought experiments disregard complexity. Intentions are foregrounded to justify moral claims. However, he gives no account that engages institutional politics and power. Research always takes place in settings made up of<strong><em> </em></strong>relations and networks of force: the compulsion to achieve objectives, the competition to acquire resources, the absence or concealment of information, and the constraints acting from above or below. Forge hardly recognizes technoscience, an enormously complex area of interconnected networks, and weapons research, a globally interconnected phenomenon which depends on a long history of knowing and doing, some of which is already applied in mundane settings (e.g. the outcomes of materials science). All these conditions and procedures are strategically backgrounded to make the author&#39;s moral system work. Our concern is that constituting a rational, moral agent as a subject of philosophical inquiry is taking the easy route. The fact that the responsibility of scientists has become a topic of inquiry for other disciplines, such as anthropology and sociology, suggests that something is wrong with this model of rational autonomy. No doubt moral philosophy employs the language of intentions, volition, decisions and choice to impose frameworks that seek<strong> </strong>to shape the conduct of scientists as responsible citizens. Our view is that in order to propose a more convincing programme of responsible action we need very detailed empirical inquiries that can grasp the situated and material conditions of technoscientific practice.</p>

  </div></div>

<div id="footer">
    <p>Copyright &copy; 2004 Notre Dame Philosophical Reviews<br />
  Site Last Modified: 3/8/2011  <br>
ISSN: 1538 - 1617</p>
    <p><a href="http://www.nd.edu/" id="ndhome">University of Notre Dame </a></p>
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-344381-6";
urchinTracker();
</script>
</div>

</div>
</body>
</html>
